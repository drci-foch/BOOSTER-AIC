{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "102557f9-7184-484b-bd0b-79795636e49b",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7759bce3-13cf-4cda-a6e8-1f01f86b305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchio as tio\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import monai\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b2901c-63ed-44ae-88bd-8bdbaacd7bb4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Filter out problematic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8537031-08db-41d9-8c64-d1fb376c5583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['06-10664-D0MR']\n",
      "['09-10683-D0MR']\n",
      "['09-10890-D0MR']\n",
      "['16-10232-D0MR']\n",
      "['21-10049-D0MR']\n",
      "['21-10049-D0MR']\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\SWI\"\n",
    "problem_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\Problem_Images\\\\SWI\"\n",
    "prev = []\n",
    "for file in os.listdir(source_dir):\n",
    "    number = file.split(\"_\")[1:2]\n",
    "    # if file.split(\"_\")[-1] == \"ph.nii.gz\":\n",
    "    #     ph_q = True\n",
    "    # else:\n",
    "    #     ph_q = False\n",
    "    if (number == prev):\n",
    "        print(number)\n",
    "        #os.rename(os.path.join(source_dir, file), os.path.join(problem_dir, file))\n",
    "    prev = number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "987fa1f8-78da-41d5-a7a2-da18b8b95351",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\TOF3D\"\n",
    "problem_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\Problem_Images\\\\TOF3D\"\n",
    "prev = []\n",
    "for file in os.listdir(source_dir):\n",
    "    number = file.split(\"_\")[1:2]\n",
    "    if \"_\".join(file.split(\"_\")[-2:]) == \"Eq_1.nii.gz\":\n",
    "        eq1_q = True\n",
    "    else:\n",
    "        eq1_q = False\n",
    "    if (number == prev) & (eq1_q):\n",
    "        os.rename(os.path.join(source_dir, file), os.path.join(problem_dir, file))\n",
    "    prev = number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc631a49-7746-496f-9fb5-2e925805c890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'16-10170-D0MR', '02-10871-D0MR', '07-10333-D0MR', '14-10034-D0MR', '21-10163-D0MR', '21-10135-D0MR', '18-10428-D0MR', '01-10221-D0MR', '14-10119-D0MR', '14-10239-D0MR', '06-10750-D0MR', '05-10410-D0MR', '30-10034-D0MR', '18-10183-D0MR', '14-10164-D0MR', '30-10085-D0MR', '06-10487-D0MR', '14-10269-D0MR', '14-10115-D0MR', '18-10542-D0MR', '18-10099-D0MR', '06-10516-D0MR', '09-10890-D0MR', '21-10158-D0MR', '02-10874-D0MR', '30-10091-D0MR', '16-10168-D0MR', '30-10092-D0MR', '30-10090-D0MR', '06-10778-D0MR', '14-10156-D0MR', '02-10555-D0MR', '17-10120-D0MR', '16-10025-D0MR', '14-10172-D0MR', '02-10878-D0MR', '14-10068-D0MR', '06-10769-D0MR', '02-10722-D0MR', '14-10153-D0MR', '14-10238-D0MR', '30-10082-D0MR', '30-10083-D0MR', '07-10335-D0MR', '14-10120-D0MR', '30-10076-D0MR', '18-10396-D0MR', '14-10123-D0MR', '18-10206-D0MR', '14-10173-D0MR', '14-10087-D0MR', '21-10049-D0MR', '30-10088-D0MR', '14-10166-D0MR', '04-10442-D0MR', '14-10125-D0MR', '30-10094-D0MR', '14-10243-D0MR', '09-10674-D0MR', '09-10683-D0MR', '09-10670-D0MR', '30-10068-D0MR', '02-10652-D0MR', '30-10089-D0MR', '02-10653-D0MR', '18-10315-D0MR', '14-10171-D0MR', '04-10209-D0MR', '05-10383-D0MR', '30-10084-D0MR', '18-10037-D0MR', '11-10071-D0MR', '16-10117-D0MR', '18-10150-D0MR', '14-10086-D0MR', '30-10070-D0MR'}\n"
     ]
    }
   ],
   "source": [
    "swi_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\SWI\"\n",
    "mask_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\MASK\"\n",
    "\n",
    "swi_numbers = [file.split(\"_\")[1:2][0] for file in os.listdir(swi_dir)]\n",
    "mask_numbers = [file.split(\"_\")[1:2][0] for file in os.listdir(mask_dir)]\n",
    "\n",
    "diff = set(mask_numbers) - set(swi_numbers)\n",
    "\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "473d4408-8c01-425e-80ba-9a1b0bb3f0c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2018-104_16-10170-D0MR_22_AX_T2_EG.nii.gz\n",
      "Processed 2018-104_02-10871-D0MR_6_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_07-10333-D0MR_20_SWI_Images.nii.gz\n",
      "Processed 2018-104_14-10034-D0MR_5_Ax_T2_.nii.gz\n",
      "Processed 2018-104_21-10163-D0MR_401_cs_T2_FFE.nii.gz\n",
      "Processed 2018-104_21-10135-D0MR_5_Ax_T2_.nii.gz\n",
      "Processed 2018-104_18-10428-D0MR_11_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_01-10221-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_14-10119-D0MR_16_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10239-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_06-10750-D0MR_8_AX_T2_EG_STD.nii.gz\n",
      "Processed 2018-104_05-10410-D0MR_12_t2_fl2d_tra_4mm_hemo_te_25.nii.gz\n",
      "Processed 2018-104_30-10034-D0MR_8_t2_fl2d_ax.nii.gz\n",
      "Processed 2018-104_18-10183-D0MR_12_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10164-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10085-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_06-10487-D0MR_9_AX_T2_EG_STD.nii.gz\n",
      "Processed 2018-104_14-10269-D0MR_16_AX_T2_.nii.gz\n",
      "Processed 2018-104_14-10115-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_18-10542-D0MR_8_AXIAL_T2_EG.nii.gz\n",
      "Processed 2018-104_18-10099-D0MR_5_Ax_T2_4mm.nii.gz\n",
      "Processed 2018-104_06-10516-D0MR_502_eAX_T2_.nii.gz\n",
      "Processed 2018-104_09-10890-D0MR_501_SWI_AVC.nii.gz\n",
      "Processed 2018-104_09-10890-D0MR_501_SWI_AVC_ph.nii.gz\n",
      "Processed 2018-104_21-10158-D0MR_401_cs_T2_FFE.nii.gz\n",
      "Processed 2018-104_02-10874-D0MR_6_Ax_eSWAN_2017.nii.gz\n",
      "Processed 2018-104_30-10091-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_16-10168-D0MR_15_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10092-D0MR_9_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10090-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_06-10778-D0MR_4_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10156-D0MR_6_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_02-10555-D0MR_5_3D_eSWAN_RAPIDE.nii.gz\n",
      "Processed 2018-104_17-10120-D0MR_6_Ax_T2_.nii.gz\n",
      "Processed 2018-104_16-10025-D0MR_12_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10172-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_02-10878-D0MR_5_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10068-D0MR_5_Ax_T2_.nii.gz\n",
      "Processed 2018-104_06-10769-D0MR_13_AX_T2_EG_STD.nii.gz\n",
      "Processed 2018-104_02-10722-D0MR_6_Ax_3D_SWAN+CARTO.nii.gz\n",
      "Processed 2018-104_14-10153-D0MR_5_3D_Ax_SWAN_4mm.nii.gz\n",
      "Processed 2018-104_14-10238-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10082-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10083-D0MR_13_SWI_Images.nii.gz\n",
      "Processed 2018-104_07-10335-D0MR_6_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10120-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10076-D0MR_8_t2_fl2d_ax.nii.gz\n",
      "Processed 2018-104_18-10396-D0MR_12_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10123-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_18-10206-D0MR_11_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10173-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_14-10087-D0MR_5_Ax_SWAN_2.4MM.nii.gz\n",
      "Processed 2018-104_21-10049-D0MR_401_SWIp.nii.gz\n",
      "Processed 2018-104_21-10049-D0MR_401_SWIp_Eq_1.nii.gz\n",
      "Processed 2018-104_21-10049-D0MR_401_SWIp_ph.nii.gz\n",
      "Processed 2018-104_30-10088-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_14-10166-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_04-10442-D0MR_14_T2_EG_TRA.nii.gz\n",
      "Processed 2018-104_14-10125-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10094-D0MR_4_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10243-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_09-10674-D0MR_5_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_09-10683-D0MR_501_SWI_AVC.nii.gz\n",
      "Processed 2018-104_09-10683-D0MR_501_SWI_AVC_ph.nii.gz\n",
      "Processed 2018-104_09-10670-D0MR_502_AXIAL_SWI.nii.gz\n",
      "Processed 2018-104_30-10068-D0MR_8_t2_fl2d_ax.nii.gz\n",
      "Processed 2018-104_02-10652-D0MR_5_Ax_SWAN.nii.gz\n",
      "Processed 2018-104_30-10089-D0MR_15_SWI_Images.nii.gz\n",
      "Processed 2018-104_02-10653-D0MR_13_AX_T2_EG.nii.gz\n",
      "Processed 2018-104_18-10315-D0MR_11_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10171-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_04-10209-D0MR_5_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_05-10383-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10084-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_18-10037-D0MR_501_T2_FFE_CS.nii.gz\n",
      "Processed 2018-104_11-10071-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_16-10117-D0MR_13_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_18-10150-D0MR_14_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10086-D0MR_6_3D_Ax_SWAN.nii.gz\n",
      "Processed 2018-104_30-10070-D0MR_8_t2_fl2d_ax.nii.gz\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"E:\\\\Data_ETIS\\\\THROMBMICS-ALARMS_20240531\"\n",
    "target_dir = \"E:\\\\Data_ETIS\\\\Temp\"\n",
    "\n",
    "for number in list(diff):\n",
    "    for directory in glob.glob(os.path.join(source_dir, \"2018-104_\"+ number, \"T2star_*\")):\n",
    "        for nii_file in os.listdir(directory):\n",
    "            os.rename(os.path.join(directory, nii_file), os.path.join(target_dir, nii_file))\n",
    "            print(\"Processed \"+ nii_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b611b762-ea53-415a-af59-a47a1073ae11",
   "metadata": {},
   "source": [
    "## Separate Test Batch of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85ffd9f8-2f8d-4b13-833a-02053ebea35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "thrombus_mask_train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_labels\\\\MASK_Train\"\n",
    "thrombus_mask_test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Test\"\n",
    "thrombus_mask_val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_labels\\\\MASK_Val\"\n",
    "foreground_mask_train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_labels\\\\MASK_Foreground_Train\"\n",
    "foreground_mask_test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Foreground_Test\"\n",
    "foreground_mask_val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_labels\\\\MASK_Foreground_Val\"\n",
    "swi_train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_dataset\\\\SWI_Train\"\n",
    "swi_test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_dataset\\\\SWI_Test\"\n",
    "swi_val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_dataset\\\\SWI_Val\"\n",
    "tof_train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_dataset\\\\TOF3D_Train\"\n",
    "tof_test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_dataset\\\\TOF3D_Test\"\n",
    "tof_val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_dataset\\\\TOF3D_Val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15cfda5e-2785-4836-ae83-889a9c3680ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_image_batch(thrombus_mask_source, thrombus_mask_destination, foreground_mask_source, foreground_mask_destination, swi_source, swi_destination, tof_source, tof_destination, batch_size, seed_value=777):\n",
    "    # Separate four source folders, thrombus mask(labels) , brain foreground masks with thrombus, swi images, tof images into four other destination folders (e.g. validation or test),\n",
    "    # sending the specified number of images selected randomly.\n",
    "    random.seed(seed_value)\n",
    "    batch_indexes = random.sample(range(len(os.listdir(thrombus_mask_source))), batch_size)\n",
    "\n",
    "    thrombus_mask_file_list = [os.listdir(thrombus_mask_source)[index] for index in batch_indexes]\n",
    "    for file in thrombus_mask_file_list:\n",
    "        os.rename(os.path.join(thrombus_mask_source, file), os.path.join(thrombus_mask_destination, file))\n",
    "\n",
    "    foreground_mask_file_list = [os.listdir(foreground_mask_source)[index] for index in batch_indexes]\n",
    "    for file in foreground_mask_file_list:\n",
    "        os.rename(os.path.join(foreground_mask_source, file), os.path.join(foreground_mask_destination, file))\n",
    "    \n",
    "    swi_file_list = [os.listdir(swi_source)[index] for index in batch_indexes]\n",
    "    for file in swi_file_list:\n",
    "        os.rename(os.path.join(swi_source, file), os.path.join(swi_destination, file))\n",
    "\n",
    "    tof_file_list = [os.listdir(tof_source)[index] for index in batch_indexes]\n",
    "    for file in tof_file_list:\n",
    "        os.rename(os.path.join(tof_source, file), os.path.join(tof_destination, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e1d3c-9c23-403f-8526-00efb1ca3d63",
   "metadata": {},
   "source": [
    "Separate test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "626d9491-7bfb-4bd3-9313-97dbe1b65efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_image_batch(thrombus_mask_train_dir, thrombus_mask_test_dir, foreground_mask_train_dir, foreground_mask_test_dir, swi_train_dir, swi_test_dir, tof_train_dir, tof_test_dir, 100, seed_value=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2501cdcb-4fc7-469c-bfe0-68f0386c28d6",
   "metadata": {},
   "source": [
    "Separate validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9ceb8cf-3ec5-480f-89c3-db6377789c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_image_batch(thrombus_mask_train_dir, thrombus_mask_val_dir, foreground_mask_train_dir, foreground_mask_val_dir, swi_train_dir, swi_val_dir, tof_train_dir, tof_val_dir, 181, seed_value=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192edc50-ce79-4d19-92b1-9c341d8a235c",
   "metadata": {},
   "source": [
    "Clear out the training folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a6f313a-6428-4483-930a-0dd5d31811e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_training_folders(thrombus_mask_train_dir, thrombus_mask_test_dir, thrombus_mask_val_dir, foreground_mask_train_dir, foreground_mask_test_dir, foreground_mask_val_dir, swi_train_dir, swi_test_dir, swi_val_dir, tof_train_dir, tof_test_dir, tof_val_dir):\n",
    "    # Remove files from training, validation and test folders of labels, foreground masks, swi images and tof images.\n",
    "    folder_list = [thrombus_mask_train_dir, thrombus_mask_test_dir, thrombus_mask_val_dir, foreground_mask_train_dir, foreground_mask_test_dir, foreground_mask_val_dir, swi_train_dir, swi_test_dir, swi_val_dir, tof_train_dir, tof_test_dir, tof_val_dir]\n",
    "    for folders in folder_list:\n",
    "        for file in os.listdir(folders):\n",
    "            os.remove(os.path.join(folders, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc04a0dc-cf1a-4b8c-af61-c0d3111a7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_training_folders(thrombus_mask_train_dir, thrombus_mask_test_dir, thrombus_mask_val_dir, foreground_mask_train_dir, foreground_mask_test_dir, foreground_mask_val_dir, swi_train_dir, swi_test_dir, swi_val_dir, tof_train_dir, tof_test_dir, tof_val_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f50055-f8bf-4c98-be7f-72b256862585",
   "metadata": {},
   "source": [
    "Fill training folders from processed images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d97d0b10-438e-4df8-a04c-3ae0c5b33db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_training_folders(source_dir, thrombus_mask_train_dir, swi_train_dir, tof_train_dir):\n",
    "    # Send images from a source folder containing MASK, SWI and TOF3D folders to the training folders.\n",
    "    for folders in os.listdir(source_dir):\n",
    "        if (folders.split(\"_\")[0] == \"MASK\") | (folders == \"MASK\"):\n",
    "            for files in os.listdir(os.path.join(source_dir, folders)):\n",
    "                os.rename(os.path.join(source_dir, folders, files), os.path.join(thrombus_mask_train_dir,files))\n",
    "        elif folders.split(\"_\")[0] == \"SWI\":\n",
    "            for files in os.listdir(os.path.join(source_dir, folders)):\n",
    "                os.rename(os.path.join(source_dir, folders, files), os.path.join(swi_train_dir,files))\n",
    "        elif folders.split(\"_\")[0] == \"TOF3D\":\n",
    "            for files in os.listdir(os.path.join(source_dir, folders)):\n",
    "                os.rename(os.path.join(source_dir, folders, files), os.path.join(tof_train_dir,files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "245da8d3-712e-4e64-ae11-09e365713ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"D:\\\\data_ETIS_781\\\\Resized\"\n",
    "\n",
    "fill_training_folders(source_dir, thrombus_mask_train_dir, swi_train_dir, tof_train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7944ba3-9b36-425b-a661-8cbbfd62772b",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "870e295a-7037-4fe4-9bfc-9e00b95faaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_array_to_nifti1(array, original_img, destination_path, output_name):\n",
    "    # Transform the array to a nifti image which requires the affine of the original image.\n",
    "    if isinstance(original_img, nib.Nifti1Image) :\n",
    "        processed_img = nib.Nifti1Image(array, nib.load(original_img).affine)\n",
    "    else:\n",
    "        processed_img = nib.Nifti1Image(array, nib.load(original_img_path).affine)\n",
    "    \n",
    "    nib.save(processed_img, os.path.join(destination_path, output_name))\n",
    "\n",
    "def remove_padding_from_tensor(tensor, original_dims):\n",
    "    # Apply the padding removal function to the tensor to restore the original dimensions\n",
    "    current_dims = tensor.shape[-len(original_dims):]\n",
    "    resized_tensor = tensor\n",
    "    \n",
    "    for dim, (original_size, current_size) in enumerate(zip(original_dims, current_dims), start=-len(original_dims)):\n",
    "        total_padding = current_size - original_size\n",
    "        padding_before = total_padding // 2\n",
    "        \n",
    "        resized_tensor = torch.narrow(resized_tensor, dim, padding_before, original_size)\n",
    "    return resized_tensor\n",
    "\n",
    "def logit_to_binary_mask(tensor, threshold=0.5):\n",
    "    # Transform a tensor of logits into a binary mask according to the specified probability threshold.\n",
    "    mask_tensor = torch.sigmoid(tensor)\n",
    "\n",
    "    return (mask_tensor >= threshold).float()\n",
    "\n",
    "def restore_inference_original_size (prediction_list, original_img_dir):\n",
    "    return [torch.squeeze(\n",
    "        remove_padding_from_tensor(prediction, nib.load(os.path.join(original_img_dir, original_file)).shape)\n",
    "        )\n",
    "        for prediction, original_file in zip(prediction_list, os.listdir(original_img_dir))\n",
    "        ]\n",
    "\n",
    "def load_prediction_masks (mask_dir):\n",
    "    return [torch.tensor(nib.load(os.path.join(mask_dir, mask)).get_fdata()) for mask in os.listdir(mask_dir) if (mask.endswith(\".nii.gz\"))]\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, filepath):\n",
    "    # Saves a checkpoint of a PyTorch model.\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    torch.save(checkpoint, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76050939-e922-464c-ae1d-addada7e527d",
   "metadata": {},
   "source": [
    "## 3D Segmentation Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f20d5-1181-44bc-91c2-dd43cd2a574d",
   "metadata": {},
   "source": [
    "### Use the SubjectsDataset class from torchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dfe9e0e0-5ee9-4620-8b7c-f4ecfd5a49be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighToleranceSubject(tio.Subject):\n",
    "    # A custom instance of Subject with higher tolerance in attribute checking.\n",
    "    def check_consistent_attribute(self, *args, **kwargs) -> None:\n",
    "        kwargs['relative_tolerance'] = 1e-4\n",
    "        kwargs['absolute_tolerance'] = 1e-4\n",
    "        return super().check_consistent_attribute(*args, **kwargs)\n",
    "\n",
    "def load_subjectsdataset_1channel (swi_dir, thrombus_labels_dir, foreground_labels_dir, **kwargs):\n",
    "    subjects_list = []\n",
    "    swi_list = os.listdir(swi_dir)\n",
    "    thrombus_labels_list = os.listdir(thrombus_labels_dir)\n",
    "    foreground_labels_list = os.listdir(foreground_labels_dir)\n",
    "    \n",
    "    if len(swi_list) != len(thrombus_labels_list) != len(foreground_labels_list):\n",
    "        print(\"Mismatch in sample numbers\")\n",
    "    \n",
    "    for swi_file, thrombus_label_file, foreground_label_file in zip(swi_list, thrombus_labels_list, foreground_labels_list):\n",
    "        subject = HighToleranceSubject(\n",
    "            swi_image=tio.ScalarImage(os.path.join(swi_dir, swi_file)),\n",
    "            thrombus_label = tio.LabelMap(os.path.join(thrombus_labels_dir, thrombus_label_file)),\n",
    "            foreground_label = tio.LabelMap(os.path.join(foreground_labels_dir, foreground_label_file)),\n",
    "            subject_number = \"_\".join(swi_file.split(\"_\")[:2])\n",
    "        )\n",
    "        subjects_list.append(subject)\n",
    "    \n",
    "    return tio.SubjectsDataset(subjects_list, **kwargs)\n",
    "\n",
    "def load_subjectsdataset_2channel (swi_dir, tof_dir, thrombus_labels_dir, foreground_labels_dir, **kwargs):\n",
    "    subjects_list = []\n",
    "    swi_list = os.listdir(swi_dir)\n",
    "    tof_list = os.listdir(tof_dir)\n",
    "    thrombus_labels_list = os.listdir(thrombus_labels_dir)\n",
    "    foreground_labels_list = os.listdir(foreground_labels_dir)\n",
    "    \n",
    "    if len(swi_list) != len(tof_list) != len(thrombus_labels_list) != len(foreground_labels_list):\n",
    "        print(\"Mismatch in sample numbers\")\n",
    "    \n",
    "    for swi_file, tof_file, thrombus_label_file, foreground_label_file in zip(swi_list, tof_list, thrombus_labels_list, foreground_labels_list):\n",
    "        subject = HighToleranceSubject(\n",
    "            swi_image=tio.ScalarImage(os.path.join(swi_dir, swi_file)),\n",
    "            tof_image=tio.ScalarImage(os.path.join(tof_dir, tof_file)),\n",
    "            thrombus_label = tio.LabelMap(os.path.join(thrombus_labels_dir, thrombus_label_file)),\n",
    "            foreground_label = tio.LabelMap(os.path.join(foreground_labels_dir, foreground_label_file)),\n",
    "            subject_number = \"_\".join(swi_file.split(\"_\")[:2])\n",
    "        )\n",
    "        subjects_list.append(subject)\n",
    "    \n",
    "    return tio.SubjectsDataset(subjects_list, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48623be8-971b-4b85-b794-76cc963d23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_train\\\\SWI_Train\"\n",
    "tof_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_train\\\\TOF3D_Train\"\n",
    "thrombus_labels_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_labels\\\\MASK_Train\"\n",
    "foreground_labels_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_labels\\\\MASK_Foreground_Train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "913d27eb-e3b9-436c-bb91-6501c7e302f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tio_dataset = load_subjectsdataset_1channel(swi_dir, thrombus_labels_dir, foreground_labels_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22be69e4-08b9-46b1-8420-dbddd5c2f88b",
   "metadata": {},
   "source": [
    "### Setup Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce12750e-23cf-4046-82f4-ec96e8c72e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tio_sampler = tio.data.LabelSampler(patch_size=(145,145,18), label_name=\"foreground_label\", label_probabilities={0: 0, 1: 0.95, 2: 0.05})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33359195",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue_length = 7000\n",
    "samples_per_volume = 1500\n",
    "\n",
    "tio_patches_queue = tio.Queue(tio_dataset, queue_length, samples_per_volume, tio_sampler, num_workers=0)\n",
    "\n",
    "tio_patches_loader = torch.utils.data.DataLoader(tio_patches_queue, batch_size=6, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d998e6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'29.6 GiB'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tio.Queue.get_max_memory_pretty(tio_patches_queue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c693769",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df1b33e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNetPlusPlus features: (32, 32, 64, 128, 256, 32).\n"
     ]
    }
   ],
   "source": [
    "model = monai.networks.nets.BasicUNetPlusPlus(spatial_dims=3, in_channels=1, out_channels=1, features=(32,32,64,128,256,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcc47e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_loss = monai.losses.FocalLoss(gamma=5, alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9eeb88ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3a28e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Training Loss: 0.0000\n",
      "Epoch 1/20, Validation Loss: 0.0001\n",
      "Epoch 2/20, Training Loss: 0.0000\n",
      "Epoch 2/20, Validation Loss: 0.0000\n",
      "Epoch 3/20, Training Loss: 0.0000\n",
      "Epoch 3/20, Validation Loss: 0.0000\n",
      "Epoch 4/20, Training Loss: 0.0000\n",
      "Epoch 4/20, Validation Loss: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 20\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tio_patches_loader)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Training Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for patches_batch in tio_patches_loader:\n",
    "        images = patches_batch[\"swi_image\"][tio.DATA]\n",
    "        gt_masks = patches_batch[\"thrombus_label\"][tio.DATA]\n",
    "        images, gt_masks = images.to(device), gt_masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predicted_mask = model(images)[0]\n",
    "        loss = focal_loss(predicted_mask, gt_masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(tio_patches_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for patches_batch in tio_patches_loader:\n",
    "            images = patches_batch[\"swi_image\"][tio.DATA]\n",
    "            gt_masks = patches_batch[\"thrombus_label\"][tio.DATA]\n",
    "            images, gt_masks = images.to(device), gt_masks.to(device)\n",
    "            \n",
    "            predicted_mask = model(images)[0]\n",
    "            loss = focal_loss(predicted_mask, gt_masks)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(tio_patches_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}\")\n",
    "    save_checkpoint(model, optimizer, epoch, loss, 'D:\\\\data_ETIS_781\\\\Training\\\\Checkpoints\\\\tio_test_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63f7e43-2794-4de5-97ee-940fc19c2a7e",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f931dec7-85a1-4e05-b9df-07a8896f28c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp3d.UnetPlusPlus(encoder_name=\"resnext50_32x4d\", encoder_weights=\"imagenet\", in_channels=2, classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6626034-0625-4563-bb86-3297f30c5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = smp.losses.DiceLoss(\"binary\", from_logits=False, smooth=1)\n",
    "focal_loss = smp.losses.FocalLoss(\"binary\", alpha=0.75, gamma=2, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8e86064-3999-4ee0-94c5-82a77c0054b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc27b33f-5880-464d-88f7-f0824e9e9d39",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m images, gt_masks \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), gt_masks\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 13\u001b[0m predicted_mask \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m dice_loss(predicted_mask, gt_masks)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m## Average the predictions in each channel\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\segmentation_models_pytorch_3d\\base\\model.py:46\u001b[0m, in \u001b[0;36mSegmentationModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input_shape(x)\n\u001b[0;32m     45\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[1;32m---> 46\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msegmentation_head(decoder_output)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassification_head \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\segmentation_models_pytorch_3d\\decoders\\unetplusplus\\decoder.py:129\u001b[0m, in \u001b[0;36mUnetPlusPlusDecoder.forward\u001b[1;34m(self, *features)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m depth_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth \u001b[38;5;241m-\u001b[39m layer_idx):\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 129\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdepth_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdepth_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdepth_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdepth_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m         dense_x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdepth_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdepth_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\segmentation_models_pytorch_3d\\decoders\\unetplusplus\\decoder.py:38\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[1;34m(self, x, skip)\u001b[0m\n\u001b[0;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(x, scale_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m skip \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention1(x)\n\u001b[0;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, gt_masks in train_dataloader:\n",
    "        images, gt_masks = images.to(device), gt_masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predicted_mask = model(images)\n",
    "        loss = dice_loss(predicted_mask, gt_masks)\n",
    "        ## Average the predictions in each channel\n",
    "        predicted_mask = predicted_mask.mean(dim=1)\n",
    "        # Transform prediction logits to probabilities\n",
    "        predicted_mask = torch.sigmoid(predicted_mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, gt_masks in val_dataloader:\n",
    "            images, gt_masks = images.to(device), gt_masks.to(device)\n",
    "            \n",
    "            predicted_mask = model(images)\n",
    "            ## Average the predictions in each channel\n",
    "            predicted_mask = predicted_mask.mean(dim=1)\n",
    "            # Transform prediction logits to probabilities\n",
    "            predicted_mask = torch.sigmoid(predicted_mask)\n",
    "            loss = dice_loss(predicted_mask, gt_masks)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a3d5d1-8a9b-46bf-ba0b-a40014a7d8ec",
   "metadata": {},
   "source": [
    "## Load model and predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b6f014",
   "metadata": {},
   "source": [
    "### Predict from patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7206679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNetPlusPlus features: (32, 32, 64, 128, 256, 32).\n"
     ]
    }
   ],
   "source": [
    "model_for_prediction = monai.networks.nets.BasicUNetPlusPlus(spatial_dims=3, in_channels=1, out_channels=1, features=(32,32,64,128,256,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6304d2f-4cb8-4eea-9d90-a50fc1206ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer_for_prediction = torch.optim.Adam(model_for_prediction.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05bb09cc-90dc-4a06-ba88-90161cf6916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_prediction_checkpoint = torch.load('D:\\\\data_ETIS_781\\\\Training\\\\Checkpoints\\\\model\\\\tio_test_10_gamma5_sigmoid05_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24ef5435-17bc-4791-92aa-61bb462af246",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_prediction.load_state_dict(model_for_prediction_checkpoint[\"model_state_dict\"])\n",
    "optimizer_for_prediction.load_state_dict(model_for_prediction_checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac5185ba-212b-4a01-8807-ee56a4a2ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_train\\\\SWI_Train\"\n",
    "train_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_labels\\\\MASK_Train\"\n",
    "train_foreground_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_labels\\\\MASK_Foreground_Train\"\n",
    "val_dir = \"\"\n",
    "val_label_dir = \"\"\n",
    "val_foreground_label_dir = \"\"\n",
    "test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_dataset\\\\SWI_Test\"\n",
    "test_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Test\"\n",
    "test_foreground_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Foreground_Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "554c9d05-434f-4d38-ae29-16face140bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = load_subjectsdataset_1channel (train_dir, train_label_dir, train_foreground_label_dir)\n",
    "#val_dataset = load_subjectsdataset_1channel (val_dir, val_label_dir, val_foreground_label_dir)\n",
    "test_dataset = load_subjectsdataset_1channel (test_dir, test_label_dir, test_foreground_label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff07c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate_fn(batch):\n",
    "    # Collate function to ensure batches have the same size, that is the size of the largest image in the batch.\n",
    "    # Find the max shape in each dimension from the batch\n",
    "    max_dims = [max([subject['swi_image'][tio.DATA].shape[-3:][d] for subject in batch]) for d in range(3)]\n",
    "    \n",
    "    # Apply padding to each image in the batch to match the largest dimensions\n",
    "    padded_subjects = []\n",
    "    for subject in batch:\n",
    "        subject_image = subject['swi_image'][tio.DATA]  # Get the image tensor\n",
    "        \n",
    "        # Calculate how much padding is needed for each dimension\n",
    "        padding = []\n",
    "        for max_dim, current_size in zip(max_dims, subject_image.shape[-3:]):\n",
    "            total_padding = max_dim - current_size\n",
    "            # Divide padding evenly across both sides\n",
    "            padding_before = total_padding // 2\n",
    "            padding_after = total_padding - padding_before  # Handle the case where the difference is odd\n",
    "            padding.extend([padding_before, padding_after])\n",
    "                \n",
    "        # Apply padding to the image\n",
    "        pad_transform = tio.Pad(padding)\n",
    "        padded_image = pad_transform(subject['swi_image'])\n",
    "        \n",
    "        # Create a new Subject with the padded image\n",
    "        padded_subject = tio.Subject(swi_image=tio.ScalarImage(tensor=padded_image[tio.DATA]))\n",
    "        padded_subjects.append(padded_subject)\n",
    "    \n",
    "    return padded_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "023a5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=6, collate_fn=pad_collate_fn, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e35164cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_for_prediction = model_for_prediction.to(device)\n",
    "\n",
    "patch_overlap = 4, 4, 4\n",
    "patch_size = 145,145,18\n",
    "inference_dataloader = test_dataloader\n",
    "logit_threshold = 0.5\n",
    "test_dir_location = test_dir\n",
    "prediction_dir_location = \"D:\\\\data_ETIS_781\\\\Training\\\\Predictions\\\\Test_Predictions\\\\SWI_Predictions\\\\Predictions_patients10_gamma5_sigmoid05\"\n",
    "ground_truth_label_location = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Test\"\n",
    "\n",
    "whole_image_predictions = []\n",
    "\n",
    "for batch in inference_dataloader:\n",
    "    for subject in batch:\n",
    "        grid_sampler = tio.inference.GridSampler(subject, patch_size, patch_overlap)\n",
    "        patch_loader = tio.SubjectsLoader(grid_sampler, batch_size=10)\n",
    "        aggregator = tio.inference.GridAggregator(grid_sampler)\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            for patches_batch in patch_loader:\n",
    "                input_tensor = patches_batch[\"swi_image\"][tio.DATA].to(device)\n",
    "                locations = patches_batch[tio.LOCATION]\n",
    "                logits = model_for_prediction(input_tensor)[0]\n",
    "                logits = logits.cpu()\n",
    "                labels = logit_to_binary_mask(logits, threshold=logit_threshold)\n",
    "                aggregator.add_batch(labels, locations)\n",
    "        whole_prediction = aggregator.get_output_tensor().cpu()\n",
    "        whole_image_predictions.append(whole_prediction)\n",
    "original_size_predictions = restore_inference_original_size(whole_image_predictions, test_dir_location)\n",
    "\n",
    "for mask, filename in zip(original_size_predictions, os.listdir(test_dir_location)):\n",
    "    output_mask_name = \"_\".join(filename.split(\"_\")[:2]) + \"_Prediction\" + \".nii.gz\"\n",
    "    save_array_to_nifti1(np.array(mask), os.path.join(test_dir, filename), prediction_dir_location, output_mask_name)\n",
    "\n",
    "ground_truth_masks_list = load_prediction_masks(ground_truth_label_location)\n",
    "\n",
    "dice_metric = monai.metrics.DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "dice_score_list = [dice_metric(prediction.unsqueeze(0).unsqueeze(0), gt_mask.unsqueeze(0).unsqueeze(0)) for prediction, gt_mask in zip(prediction_list, ground_truth_masks_list)]\n",
    "print(f\"Mean Dice Score is {np.array(dice_score_list).flatten().mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85a6a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference (inference_dataloader, model_for_prediction, patch_size, patch_overlap, inference_dir_location, return_logits=True, patch_loader_batchsize=10, logit_threshold=0.5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    whole_image_predictions = []\n",
    "\n",
    "    for batch in inference_dataloader:\n",
    "        for subject in batch:\n",
    "            grid_sampler = tio.inference.GridSampler(subject, patch_size, patch_overlap)\n",
    "            patch_loader = tio.SubjectsLoader(grid_sampler, batch_size=patch_loader_batchsize)\n",
    "            aggregator = tio.inference.GridAggregator(grid_sampler)\n",
    "            \n",
    "            with torch.no_grad(): \n",
    "                for patches_batch in patch_loader:\n",
    "                    input_tensor = patches_batch[\"swi_image\"][tio.DATA].to(device)\n",
    "                    locations = patches_batch[tio.LOCATION]\n",
    "                    logits = model_for_prediction(input_tensor)[0]\n",
    "                    logits = logits.cpu()\n",
    "                    if return_logits == False:\n",
    "                        labels = logit_to_binary_mask(logits, threshold=logit_threshold)\n",
    "                        aggregator.add_batch(labels, locations)\n",
    "                    else:\n",
    "                        aggregator.add_batch(logits, locations)\n",
    "            whole_prediction = aggregator.get_output_tensor().cpu()\n",
    "            whole_image_predictions.append(whole_prediction)\n",
    "    return restore_inference_original_size(whole_image_predictions, inference_dir_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82465c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions (predictions_list, save_destination, filename_source_dir):\n",
    "    for mask, filename in zip(predictions_list, os.listdir(filename_source_dir)):\n",
    "        output_mask_name = \"_\".join(filename.split(\"_\")[:2]) + \"_Prediction\" + \".nii.gz\"\n",
    "        save_array_to_nifti1(np.array(mask), os.path.join(filename_source_dir, filename), save_destination, output_mask_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e83126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dice_metric (prediction_list, ground_truth_masks_list):\n",
    "    dice_metric = monai.metrics.DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "    dice_score_list = np.array(\n",
    "        [dice_metric(prediction.unsqueeze(0).unsqueeze(0), gt_mask.unsqueeze(0).unsqueeze(0))\n",
    "         for prediction, gt_mask in zip(prediction_list, ground_truth_masks_list)]\n",
    "        ).flatten()\n",
    "    print(f\"Mean Dice Score is {dice_score_list.mean()}\")\n",
    "    return dice_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448af008",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dir_location = \"D:\\\\data_ETIS_781\\\\Training\\\\Predictions\\\\Test_Predictions\\\\SWI_Predictions\\\\Predictions_patients10_gamma5_sigmoid07\"\n",
    "ground_truth_label_location = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Test\"\n",
    "\n",
    "logits_list = run_inference(test_dataloader, model_for_prediction, (145,145,18), (4, 4, 4), test_dir, return_logits=True)\n",
    "predictions_list = [logit_to_binary_mask(logits, threshold=0.7) for logits in logits_list]\n",
    "save_predictions(predictions_list, prediction_dir_location, test_dir)\n",
    "ground_truth_masks_list = load_prediction_masks(ground_truth_label_location)\n",
    "dice_score_list = compute_dice_metric(predictions_list, ground_truth_masks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7fd0c086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts, bins, patches = plt.hist(np.array(dice_score_list).flatten(), bins=20)\n",
    "\n",
    "for count, x in zip(counts, bins):\n",
    "    plt.text(x + 0.02, count, str(int(count)), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.xlabel(\"Dice Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Dice Score statistic 10x1500 patches | gamma 5 | sigmoid 0.5\")\n",
    "plt.savefig(\"D:\\\\data_ETIS_781\\\\Training\\\\Checkpoints\\\\Dice_Results\\\\DiceScoreStatistic_10x1500patches_gamma5_sigmoid05.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e337e4",
   "metadata": {},
   "source": [
    "### Predict from whole images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "659087c6-76ae-44ab-b88f-1f2a46def0d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 512, 512, 24] at entry 0 and [1, 512, 512, 115] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m all_predictions_first \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicted_mask_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_for_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type(\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\u001b[43m}\u001b[49m)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type(\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\u001b[43m}\u001b[49m)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 512, 512, 24] at entry 0 and [1, 512, 512, 115] at entry 1"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "all_predictions_mean = []\n",
    "all_predictions_first = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, test_labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        predicted_mask_test = model_for_prediction(images)\n",
    "\n",
    "        predicted_mask_test_mean = predicted_mask_test.mean(dim=1)\n",
    "        predicted_mask_test_first = predicted_mask_test[:,0,:,:]\n",
    "\n",
    "        all_predictions_mean.append(predicted_mask_test_mean.cpu())\n",
    "        all_predictions_first.append(predicted_mask_test_first.cpu())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14820ab-ee9a-4089-ba50-ed63458882b7",
   "metadata": {},
   "source": [
    "## Testing ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcca993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
