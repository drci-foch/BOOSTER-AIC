{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "102557f9-7184-484b-bd0b-79795636e49b",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7759bce3-13cf-4cda-a6e8-1f01f86b305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchio as tio\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import monai\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b2901c-63ed-44ae-88bd-8bdbaacd7bb4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Filter out problematic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8537031-08db-41d9-8c64-d1fb376c5583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['06-10664-D0MR']\n",
      "['09-10683-D0MR']\n",
      "['09-10890-D0MR']\n",
      "['16-10232-D0MR']\n",
      "['21-10049-D0MR']\n",
      "['21-10049-D0MR']\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\SWI\"\n",
    "problem_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\Problem_Images\\\\SWI\"\n",
    "prev = []\n",
    "for file in os.listdir(source_dir):\n",
    "    number = file.split(\"_\")[1:2]\n",
    "    # if file.split(\"_\")[-1] == \"ph.nii.gz\":\n",
    "    #     ph_q = True\n",
    "    # else:\n",
    "    #     ph_q = False\n",
    "    if (number == prev):\n",
    "        print(number)\n",
    "        #os.rename(os.path.join(source_dir, file), os.path.join(problem_dir, file))\n",
    "    prev = number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "987fa1f8-78da-41d5-a7a2-da18b8b95351",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\TOF3D\"\n",
    "problem_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\Problem_Images\\\\TOF3D\"\n",
    "prev = []\n",
    "for file in os.listdir(source_dir):\n",
    "    number = file.split(\"_\")[1:2]\n",
    "    if \"_\".join(file.split(\"_\")[-2:]) == \"Eq_1.nii.gz\":\n",
    "        eq1_q = True\n",
    "    else:\n",
    "        eq1_q = False\n",
    "    if (number == prev) & (eq1_q):\n",
    "        os.rename(os.path.join(source_dir, file), os.path.join(problem_dir, file))\n",
    "    prev = number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc631a49-7746-496f-9fb5-2e925805c890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'16-10170-D0MR', '02-10871-D0MR', '07-10333-D0MR', '14-10034-D0MR', '21-10163-D0MR', '21-10135-D0MR', '18-10428-D0MR', '01-10221-D0MR', '14-10119-D0MR', '14-10239-D0MR', '06-10750-D0MR', '05-10410-D0MR', '30-10034-D0MR', '18-10183-D0MR', '14-10164-D0MR', '30-10085-D0MR', '06-10487-D0MR', '14-10269-D0MR', '14-10115-D0MR', '18-10542-D0MR', '18-10099-D0MR', '06-10516-D0MR', '09-10890-D0MR', '21-10158-D0MR', '02-10874-D0MR', '30-10091-D0MR', '16-10168-D0MR', '30-10092-D0MR', '30-10090-D0MR', '06-10778-D0MR', '14-10156-D0MR', '02-10555-D0MR', '17-10120-D0MR', '16-10025-D0MR', '14-10172-D0MR', '02-10878-D0MR', '14-10068-D0MR', '06-10769-D0MR', '02-10722-D0MR', '14-10153-D0MR', '14-10238-D0MR', '30-10082-D0MR', '30-10083-D0MR', '07-10335-D0MR', '14-10120-D0MR', '30-10076-D0MR', '18-10396-D0MR', '14-10123-D0MR', '18-10206-D0MR', '14-10173-D0MR', '14-10087-D0MR', '21-10049-D0MR', '30-10088-D0MR', '14-10166-D0MR', '04-10442-D0MR', '14-10125-D0MR', '30-10094-D0MR', '14-10243-D0MR', '09-10674-D0MR', '09-10683-D0MR', '09-10670-D0MR', '30-10068-D0MR', '02-10652-D0MR', '30-10089-D0MR', '02-10653-D0MR', '18-10315-D0MR', '14-10171-D0MR', '04-10209-D0MR', '05-10383-D0MR', '30-10084-D0MR', '18-10037-D0MR', '11-10071-D0MR', '16-10117-D0MR', '18-10150-D0MR', '14-10086-D0MR', '30-10070-D0MR'}\n"
     ]
    }
   ],
   "source": [
    "swi_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\SWI\"\n",
    "mask_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\MASK\"\n",
    "\n",
    "swi_numbers = [file.split(\"_\")[1:2][0] for file in os.listdir(swi_dir)]\n",
    "mask_numbers = [file.split(\"_\")[1:2][0] for file in os.listdir(mask_dir)]\n",
    "\n",
    "diff = set(mask_numbers) - set(swi_numbers)\n",
    "\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "473d4408-8c01-425e-80ba-9a1b0bb3f0c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2018-104_16-10170-D0MR_22_AX_T2_EG.nii.gz\n",
      "Processed 2018-104_02-10871-D0MR_6_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_07-10333-D0MR_20_SWI_Images.nii.gz\n",
      "Processed 2018-104_14-10034-D0MR_5_Ax_T2_.nii.gz\n",
      "Processed 2018-104_21-10163-D0MR_401_cs_T2_FFE.nii.gz\n",
      "Processed 2018-104_21-10135-D0MR_5_Ax_T2_.nii.gz\n",
      "Processed 2018-104_18-10428-D0MR_11_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_01-10221-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_14-10119-D0MR_16_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10239-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_06-10750-D0MR_8_AX_T2_EG_STD.nii.gz\n",
      "Processed 2018-104_05-10410-D0MR_12_t2_fl2d_tra_4mm_hemo_te_25.nii.gz\n",
      "Processed 2018-104_30-10034-D0MR_8_t2_fl2d_ax.nii.gz\n",
      "Processed 2018-104_18-10183-D0MR_12_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10164-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10085-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_06-10487-D0MR_9_AX_T2_EG_STD.nii.gz\n",
      "Processed 2018-104_14-10269-D0MR_16_AX_T2_.nii.gz\n",
      "Processed 2018-104_14-10115-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_18-10542-D0MR_8_AXIAL_T2_EG.nii.gz\n",
      "Processed 2018-104_18-10099-D0MR_5_Ax_T2_4mm.nii.gz\n",
      "Processed 2018-104_06-10516-D0MR_502_eAX_T2_.nii.gz\n",
      "Processed 2018-104_09-10890-D0MR_501_SWI_AVC.nii.gz\n",
      "Processed 2018-104_09-10890-D0MR_501_SWI_AVC_ph.nii.gz\n",
      "Processed 2018-104_21-10158-D0MR_401_cs_T2_FFE.nii.gz\n",
      "Processed 2018-104_02-10874-D0MR_6_Ax_eSWAN_2017.nii.gz\n",
      "Processed 2018-104_30-10091-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_16-10168-D0MR_15_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10092-D0MR_9_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10090-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_06-10778-D0MR_4_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10156-D0MR_6_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_02-10555-D0MR_5_3D_eSWAN_RAPIDE.nii.gz\n",
      "Processed 2018-104_17-10120-D0MR_6_Ax_T2_.nii.gz\n",
      "Processed 2018-104_16-10025-D0MR_12_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10172-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_02-10878-D0MR_5_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10068-D0MR_5_Ax_T2_.nii.gz\n",
      "Processed 2018-104_06-10769-D0MR_13_AX_T2_EG_STD.nii.gz\n",
      "Processed 2018-104_02-10722-D0MR_6_Ax_3D_SWAN+CARTO.nii.gz\n",
      "Processed 2018-104_14-10153-D0MR_5_3D_Ax_SWAN_4mm.nii.gz\n",
      "Processed 2018-104_14-10238-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10082-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10083-D0MR_13_SWI_Images.nii.gz\n",
      "Processed 2018-104_07-10335-D0MR_6_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10120-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10076-D0MR_8_t2_fl2d_ax.nii.gz\n",
      "Processed 2018-104_18-10396-D0MR_12_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10123-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_18-10206-D0MR_11_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10173-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_14-10087-D0MR_5_Ax_SWAN_2.4MM.nii.gz\n",
      "Processed 2018-104_21-10049-D0MR_401_SWIp.nii.gz\n",
      "Processed 2018-104_21-10049-D0MR_401_SWIp_Eq_1.nii.gz\n",
      "Processed 2018-104_21-10049-D0MR_401_SWIp_ph.nii.gz\n",
      "Processed 2018-104_30-10088-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_14-10166-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_04-10442-D0MR_14_T2_EG_TRA.nii.gz\n",
      "Processed 2018-104_14-10125-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10094-D0MR_4_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10243-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_09-10674-D0MR_5_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_09-10683-D0MR_501_SWI_AVC.nii.gz\n",
      "Processed 2018-104_09-10683-D0MR_501_SWI_AVC_ph.nii.gz\n",
      "Processed 2018-104_09-10670-D0MR_502_AXIAL_SWI.nii.gz\n",
      "Processed 2018-104_30-10068-D0MR_8_t2_fl2d_ax.nii.gz\n",
      "Processed 2018-104_02-10652-D0MR_5_Ax_SWAN.nii.gz\n",
      "Processed 2018-104_30-10089-D0MR_15_SWI_Images.nii.gz\n",
      "Processed 2018-104_02-10653-D0MR_13_AX_T2_EG.nii.gz\n",
      "Processed 2018-104_18-10315-D0MR_11_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10171-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_04-10209-D0MR_5_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_05-10383-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10084-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_18-10037-D0MR_501_T2_FFE_CS.nii.gz\n",
      "Processed 2018-104_11-10071-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_16-10117-D0MR_13_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_18-10150-D0MR_14_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10086-D0MR_6_3D_Ax_SWAN.nii.gz\n",
      "Processed 2018-104_30-10070-D0MR_8_t2_fl2d_ax.nii.gz\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"E:\\\\Data_ETIS\\\\THROMBMICS-ALARMS_20240531\"\n",
    "target_dir = \"E:\\\\Data_ETIS\\\\Temp\"\n",
    "\n",
    "for number in list(diff):\n",
    "    for directory in glob.glob(os.path.join(source_dir, \"2018-104_\"+ number, \"T2star_*\")):\n",
    "        for nii_file in os.listdir(directory):\n",
    "            os.rename(os.path.join(directory, nii_file), os.path.join(target_dir, nii_file))\n",
    "            print(\"Processed \"+ nii_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b611b762-ea53-415a-af59-a47a1073ae11",
   "metadata": {},
   "source": [
    "## Separate Test Batch of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85ffd9f8-2f8d-4b13-833a-02053ebea35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "thrombus_mask_train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_labels\\\\MASK_Train\"\n",
    "thrombus_mask_test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Test\"\n",
    "thrombus_mask_val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_labels\\\\MASK_Val\"\n",
    "foreground_mask_train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_labels\\\\MASK_Foreground_Train\"\n",
    "foreground_mask_test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Foreground_Test\"\n",
    "foreground_mask_val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_labels\\\\MASK_Foreground_Val\"\n",
    "swi_train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_dataset\\\\SWI_Train\"\n",
    "swi_test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_dataset\\\\SWI_Test\"\n",
    "swi_val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_dataset\\\\SWI_Val\"\n",
    "tof_train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_dataset\\\\TOF3D_Train\"\n",
    "tof_test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_dataset\\\\TOF3D_Test\"\n",
    "tof_val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_dataset\\\\TOF3D_Val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15cfda5e-2785-4836-ae83-889a9c3680ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_image_batch(thrombus_mask_source, thrombus_mask_destination, foreground_mask_source, foreground_mask_destination, swi_source, swi_destination, tof_source, tof_destination, batch_size, seed_value=777):\n",
    "    # Separate four source folders, thrombus mask(labels) , brain foreground masks with thrombus, swi images, tof images into four other destination folders (e.g. validation or test),\n",
    "    # sending the specified number of images selected randomly.\n",
    "    random.seed(seed_value)\n",
    "    batch_indexes = random.sample(range(len(os.listdir(thrombus_mask_source))), batch_size)\n",
    "\n",
    "    thrombus_mask_file_list = [os.listdir(thrombus_mask_source)[index] for index in batch_indexes]\n",
    "    for file in thrombus_mask_file_list:\n",
    "        os.rename(os.path.join(thrombus_mask_source, file), os.path.join(thrombus_mask_destination, file))\n",
    "\n",
    "    foreground_mask_file_list = [os.listdir(foreground_mask_source)[index] for index in batch_indexes]\n",
    "    for file in foreground_mask_file_list:\n",
    "        os.rename(os.path.join(foreground_mask_source, file), os.path.join(foreground_mask_destination, file))\n",
    "    \n",
    "    swi_file_list = [os.listdir(swi_source)[index] for index in batch_indexes]\n",
    "    for file in swi_file_list:\n",
    "        os.rename(os.path.join(swi_source, file), os.path.join(swi_destination, file))\n",
    "\n",
    "    tof_file_list = [os.listdir(tof_source)[index] for index in batch_indexes]\n",
    "    for file in tof_file_list:\n",
    "        os.rename(os.path.join(tof_source, file), os.path.join(tof_destination, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e1d3c-9c23-403f-8526-00efb1ca3d63",
   "metadata": {},
   "source": [
    "Separate test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "626d9491-7bfb-4bd3-9313-97dbe1b65efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_image_batch(thrombus_mask_train_dir, thrombus_mask_test_dir, foreground_mask_train_dir, foreground_mask_test_dir, swi_train_dir, swi_test_dir, tof_train_dir, tof_test_dir, 100, seed_value=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2501cdcb-4fc7-469c-bfe0-68f0386c28d6",
   "metadata": {},
   "source": [
    "Separate validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9ceb8cf-3ec5-480f-89c3-db6377789c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_image_batch(thrombus_mask_train_dir, thrombus_mask_val_dir, foreground_mask_train_dir, foreground_mask_val_dir, swi_train_dir, swi_val_dir, tof_train_dir, tof_val_dir, 181, seed_value=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192edc50-ce79-4d19-92b1-9c341d8a235c",
   "metadata": {},
   "source": [
    "Clear out the training folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a6f313a-6428-4483-930a-0dd5d31811e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_training_folders(thrombus_mask_train_dir, thrombus_mask_test_dir, thrombus_mask_val_dir, foreground_mask_train_dir, foreground_mask_test_dir, foreground_mask_val_dir, swi_train_dir, swi_test_dir, swi_val_dir, tof_train_dir, tof_test_dir, tof_val_dir):\n",
    "    # Remove files from training, validation and test folders of labels, foreground masks, swi images and tof images.\n",
    "    folder_list = [thrombus_mask_train_dir, thrombus_mask_test_dir, thrombus_mask_val_dir, foreground_mask_train_dir, foreground_mask_test_dir, foreground_mask_val_dir, swi_train_dir, swi_test_dir, swi_val_dir, tof_train_dir, tof_test_dir, tof_val_dir]\n",
    "    for folders in folder_list:\n",
    "        for file in os.listdir(folders):\n",
    "            os.remove(os.path.join(folders, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc04a0dc-cf1a-4b8c-af61-c0d3111a7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_training_folders(thrombus_mask_train_dir, thrombus_mask_test_dir, thrombus_mask_val_dir, foreground_mask_train_dir, foreground_mask_test_dir, foreground_mask_val_dir, swi_train_dir, swi_test_dir, swi_val_dir, tof_train_dir, tof_test_dir, tof_val_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f50055-f8bf-4c98-be7f-72b256862585",
   "metadata": {},
   "source": [
    "Fill training folders from processed images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d97d0b10-438e-4df8-a04c-3ae0c5b33db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_training_folders(source_dir, thrombus_mask_train_dir, swi_train_dir, tof_train_dir):\n",
    "    # Send images from a source folder containing MASK, SWI and TOF3D folders to the training folders.\n",
    "    for folders in os.listdir(source_dir):\n",
    "        if (folders.split(\"_\")[0] == \"MASK\") | (folders == \"MASK\"):\n",
    "            for files in os.listdir(os.path.join(source_dir, folders)):\n",
    "                os.rename(os.path.join(source_dir, folders, files), os.path.join(thrombus_mask_train_dir,files))\n",
    "        elif folders.split(\"_\")[0] == \"SWI\":\n",
    "            for files in os.listdir(os.path.join(source_dir, folders)):\n",
    "                os.rename(os.path.join(source_dir, folders, files), os.path.join(swi_train_dir,files))\n",
    "        elif folders.split(\"_\")[0] == \"TOF3D\":\n",
    "            for files in os.listdir(os.path.join(source_dir, folders)):\n",
    "                os.rename(os.path.join(source_dir, folders, files), os.path.join(tof_train_dir,files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "245da8d3-712e-4e64-ae11-09e365713ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"D:\\\\data_ETIS_781\\\\Resized\"\n",
    "\n",
    "fill_training_folders(source_dir, thrombus_mask_train_dir, swi_train_dir, tof_train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7944ba3-9b36-425b-a661-8cbbfd62772b",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "870e295a-7037-4fe4-9bfc-9e00b95faaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_array_to_nifti1(array, original_img_path, destination_path, output_name):\n",
    "    # Transform the array to a nifti image which requires the affine of the original image.\n",
    "    processed_img = nib.Nifti1Image(array, nib.load(original_img_path).affine)\n",
    "    \n",
    "    nib.save(processed_img, os.path.join(destination_path, output_name))\n",
    "\n",
    "def remove_padding_from_tensor(tensor, original_dims):\n",
    "    # Apply the padding removal function to the tensor to restore the original dimensions\n",
    "    current_dims = tensor.shape[-len(original_dims):]\n",
    "    resized_tensor = tensor\n",
    "    \n",
    "    for dim, (original_size, current_size) in enumerate(zip(original_dims, current_dims), start=-len(original_dims)):\n",
    "        total_padding = current_size - original_size\n",
    "        padding_before = total_padding // 2\n",
    "        \n",
    "        resized_tensor = torch.narrow(resized_tensor, dim, padding_before, original_size)\n",
    "    return resized_tensor\n",
    "\n",
    "def logit_to_binary_mask(tensor, threshold=0.5):\n",
    "    # Transform a tensor of logits into a binary mask according to the specified probability threshold.\n",
    "    mask_tensor = torch.sigmoid(tensor)\n",
    "\n",
    "    return (mask_tensor >= threshold).float()\n",
    "\n",
    "def restore_inference_original_size (prediction_list, original_img_dir):\n",
    "    return [torch.squeeze(\n",
    "        remove_padding_from_tensor(prediction, nib.load(os.path.join(original_img_dir, original_file)).shape)\n",
    "        )\n",
    "        for prediction, original_file in zip(prediction_list, os.listdir(original_img_dir))\n",
    "        ]\n",
    "\n",
    "def load_prediction_masks (mask_dir):\n",
    "    return [torch.tensor(nib.load(os.path.join(mask_dir, mask)).get_fdata()) for mask in os.listdir(mask_dir) if (mask.endswith(\".nii.gz\"))]\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, filepath):\n",
    "    # Saves a checkpoint of a PyTorch model.\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    torch.save(checkpoint, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76050939-e922-464c-ae1d-addada7e527d",
   "metadata": {},
   "source": [
    "## 3D Segmentation Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f20d5-1181-44bc-91c2-dd43cd2a574d",
   "metadata": {},
   "source": [
    "### Use the SubjectsDataset class from torchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfe9e0e0-5ee9-4620-8b7c-f4ecfd5a49be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighToleranceSubject(tio.Subject):\n",
    "    # A custom instance of Subject with higher tolerance in attribute checking.\n",
    "    def check_consistent_attribute(self, *args, **kwargs) -> None:\n",
    "        kwargs['relative_tolerance'] = 1e-4\n",
    "        kwargs['absolute_tolerance'] = 1e-4\n",
    "        return super().check_consistent_attribute(*args, **kwargs)\n",
    "\n",
    "def load_subjectsdataset_1channel (swi_dir, thrombus_labels_dir, foreground_labels_dir, **kwargs):\n",
    "    subjects_list = []\n",
    "    swi_list = os.listdir(swi_dir)\n",
    "    thrombus_labels_list = os.listdir(thrombus_labels_dir)\n",
    "    foreground_labels_list = os.listdir(foreground_labels_dir)\n",
    "    \n",
    "    if len(swi_list) != len(thrombus_labels_list) != len(foreground_labels_list):\n",
    "        print(\"Mismatch in sample numbers\")\n",
    "    \n",
    "    for swi_file, thrombus_label_file, foreground_label_file in zip(swi_list, thrombus_labels_list, foreground_labels_list):\n",
    "        subject = HighToleranceSubject(\n",
    "            swi_image=tio.ScalarImage(os.path.join(swi_dir, swi_file)),\n",
    "            thrombus_label = tio.LabelMap(os.path.join(thrombus_labels_dir, thrombus_label_file)),\n",
    "            foreground_label = tio.LabelMap(os.path.join(foreground_labels_dir, foreground_label_file)),\n",
    "            subject_number = \"_\".join(swi_file.split(\"_\")[:2])\n",
    "        )\n",
    "        subjects_list.append(subject)\n",
    "    \n",
    "    return tio.SubjectsDataset(subjects_list, **kwargs)\n",
    "\n",
    "def load_subjectsdataset_2channel (swi_dir, tof_dir, thrombus_labels_dir, foreground_labels_dir, **kwargs):\n",
    "    subjects_list = []\n",
    "    swi_list = os.listdir(swi_dir)\n",
    "    tof_list = os.listdir(tof_dir)\n",
    "    thrombus_labels_list = os.listdir(thrombus_labels_dir)\n",
    "    foreground_labels_list = os.listdir(foreground_labels_dir)\n",
    "    \n",
    "    if len(swi_list) != len(tof_list) != len(thrombus_labels_list) != len(foreground_labels_list):\n",
    "        print(\"Mismatch in sample numbers\")\n",
    "    \n",
    "    for swi_file, tof_file, thrombus_label_file, foreground_label_file in zip(swi_list, tof_list, thrombus_labels_list, foreground_labels_list):\n",
    "        subject = HighToleranceSubject(\n",
    "            swi_image=tio.ScalarImage(os.path.join(swi_dir, swi_file)),\n",
    "            tof_image=tio.ScalarImage(os.path.join(tof_dir, tof_file)),\n",
    "            thrombus_label = tio.LabelMap(os.path.join(thrombus_labels_dir, thrombus_label_file)),\n",
    "            foreground_label = tio.LabelMap(os.path.join(foreground_labels_dir, foreground_label_file)),\n",
    "            subject_number = \"_\".join(swi_file.split(\"_\")[:2])\n",
    "        )\n",
    "        subjects_list.append(subject)\n",
    "    \n",
    "    return tio.SubjectsDataset(subjects_list, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48623be8-971b-4b85-b794-76cc963d23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_train\\\\SWI_Train\"\n",
    "tof_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_train\\\\TOF3D_Train\"\n",
    "thrombus_labels_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_labels\\\\MASK_Train\"\n",
    "foreground_labels_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_labels\\\\MASK_Foreground_Train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "913d27eb-e3b9-436c-bb91-6501c7e302f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tio_dataset = load_subjectsdataset_1channel(swi_dir, thrombus_labels_dir, foreground_labels_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22be69e4-08b9-46b1-8420-dbddd5c2f88b",
   "metadata": {},
   "source": [
    "### Setup Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce12750e-23cf-4046-82f4-ec96e8c72e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tio_sampler = tio.data.LabelSampler(patch_size=(145,145,18), label_name=\"foreground_label\", label_probabilities={0: 0, 1: 0.95, 2: 0.05})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33359195",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue_length = 7000\n",
    "samples_per_volume = 1500\n",
    "\n",
    "tio_patches_queue = tio.Queue(tio_dataset, queue_length, samples_per_volume, tio_sampler, num_workers=0)\n",
    "\n",
    "tio_patches_loader = torch.utils.data.DataLoader(tio_patches_queue, batch_size=6, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d998e6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'29.6 GiB'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tio.Queue.get_max_memory_pretty(tio_patches_queue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c693769",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df1b33e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNetPlusPlus features: (32, 32, 64, 128, 256, 32).\n"
     ]
    }
   ],
   "source": [
    "model = monai.networks.nets.BasicUNetPlusPlus(spatial_dims=3, in_channels=1, out_channels=1, features=(32,32,64,128,256,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcc47e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_loss = monai.losses.FocalLoss(gamma=5, alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9eeb88ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3a28e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Training Loss: 0.0000\n",
      "Epoch 1/20, Validation Loss: 0.0001\n",
      "Epoch 2/20, Training Loss: 0.0000\n",
      "Epoch 2/20, Validation Loss: 0.0000\n",
      "Epoch 3/20, Training Loss: 0.0000\n",
      "Epoch 3/20, Validation Loss: 0.0000\n",
      "Epoch 4/20, Training Loss: 0.0000\n",
      "Epoch 4/20, Validation Loss: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 20\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tio_patches_loader)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Training Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for patches_batch in tio_patches_loader:\n",
    "        images = patches_batch[\"swi_image\"][tio.DATA]\n",
    "        gt_masks = patches_batch[\"thrombus_label\"][tio.DATA]\n",
    "        images, gt_masks = images.to(device), gt_masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predicted_mask = model(images)[0]\n",
    "        loss = focal_loss(predicted_mask, gt_masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(tio_patches_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for patches_batch in tio_patches_loader:\n",
    "            images = patches_batch[\"swi_image\"][tio.DATA]\n",
    "            gt_masks = patches_batch[\"thrombus_label\"][tio.DATA]\n",
    "            images, gt_masks = images.to(device), gt_masks.to(device)\n",
    "            \n",
    "            predicted_mask = model(images)[0]\n",
    "            loss = focal_loss(predicted_mask, gt_masks)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(tio_patches_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}\")\n",
    "    save_checkpoint(model, optimizer, epoch, loss, 'D:\\\\data_ETIS_781\\\\Training\\\\Checkpoints\\\\tio_test_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63f7e43-2794-4de5-97ee-940fc19c2a7e",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f931dec7-85a1-4e05-b9df-07a8896f28c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp3d.UnetPlusPlus(encoder_name=\"resnext50_32x4d\", encoder_weights=\"imagenet\", in_channels=2, classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6626034-0625-4563-bb86-3297f30c5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = smp.losses.DiceLoss(\"binary\", from_logits=False, smooth=1)\n",
    "focal_loss = smp.losses.FocalLoss(\"binary\", alpha=0.75, gamma=2, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8e86064-3999-4ee0-94c5-82a77c0054b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc27b33f-5880-464d-88f7-f0824e9e9d39",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m images, gt_masks \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), gt_masks\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 13\u001b[0m predicted_mask \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m dice_loss(predicted_mask, gt_masks)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m## Average the predictions in each channel\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\segmentation_models_pytorch_3d\\base\\model.py:46\u001b[0m, in \u001b[0;36mSegmentationModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input_shape(x)\n\u001b[0;32m     45\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[1;32m---> 46\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msegmentation_head(decoder_output)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassification_head \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\segmentation_models_pytorch_3d\\decoders\\unetplusplus\\decoder.py:129\u001b[0m, in \u001b[0;36mUnetPlusPlusDecoder.forward\u001b[1;34m(self, *features)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m depth_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth \u001b[38;5;241m-\u001b[39m layer_idx):\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 129\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdepth_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdepth_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdepth_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdepth_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m         dense_x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdepth_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdepth_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\segmentation_models_pytorch_3d\\decoders\\unetplusplus\\decoder.py:38\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[1;34m(self, x, skip)\u001b[0m\n\u001b[0;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(x, scale_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m skip \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention1(x)\n\u001b[0;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, gt_masks in train_dataloader:\n",
    "        images, gt_masks = images.to(device), gt_masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predicted_mask = model(images)\n",
    "        loss = dice_loss(predicted_mask, gt_masks)\n",
    "        ## Average the predictions in each channel\n",
    "        predicted_mask = predicted_mask.mean(dim=1)\n",
    "        # Transform prediction logits to probabilities\n",
    "        predicted_mask = torch.sigmoid(predicted_mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, gt_masks in val_dataloader:\n",
    "            images, gt_masks = images.to(device), gt_masks.to(device)\n",
    "            \n",
    "            predicted_mask = model(images)\n",
    "            ## Average the predictions in each channel\n",
    "            predicted_mask = predicted_mask.mean(dim=1)\n",
    "            # Transform prediction logits to probabilities\n",
    "            predicted_mask = torch.sigmoid(predicted_mask)\n",
    "            loss = dice_loss(predicted_mask, gt_masks)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a3d5d1-8a9b-46bf-ba0b-a40014a7d8ec",
   "metadata": {},
   "source": [
    "## Load model and predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b6f014",
   "metadata": {},
   "source": [
    "### Predict from patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7206679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNetPlusPlus features: (32, 32, 64, 128, 256, 32).\n"
     ]
    }
   ],
   "source": [
    "model_for_prediction = monai.networks.nets.BasicUNetPlusPlus(spatial_dims=3, in_channels=1, out_channels=1, features=(32,32,64,128,256,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6304d2f-4cb8-4eea-9d90-a50fc1206ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer_for_prediction = torch.optim.Adam(model_for_prediction.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05bb09cc-90dc-4a06-ba88-90161cf6916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_prediction_checkpoint = torch.load('D:\\\\data_ETIS_781\\\\Training\\\\Checkpoints\\\\tio_test_10_gamma5_thrombus05_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24ef5435-17bc-4791-92aa-61bb462af246",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_prediction.load_state_dict(model_for_prediction_checkpoint[\"model_state_dict\"])\n",
    "optimizer_for_prediction.load_state_dict(model_for_prediction_checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac5185ba-212b-4a01-8807-ee56a4a2ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_train\\\\SWI_Train\"\n",
    "train_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_labels\\\\MASK_Train\"\n",
    "train_foreground_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_labels\\\\MASK_Foreground_Train\"\n",
    "val_dir = \"\"\n",
    "val_label_dir = \"\"\n",
    "val_foreground_label_dir = \"\"\n",
    "test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_dataset\\\\SWI_Test\"\n",
    "test_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Test\"\n",
    "test_foreground_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Foreground_Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "554c9d05-434f-4d38-ae29-16face140bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = load_subjectsdataset_1channel (train_dir, train_label_dir, train_foreground_label_dir)\n",
    "#val_dataset = load_subjectsdataset_1channel (val_dir, val_label_dir, val_foreground_label_dir)\n",
    "test_dataset = load_subjectsdataset_1channel (test_dir, test_label_dir, test_foreground_label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff07c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate_fn(batch):\n",
    "    # Collate function to ensure batches have the same size, that is the size of the largest image in the batch.\n",
    "    # Find the max shape in each dimension from the batch\n",
    "    max_dims = [max([subject['swi_image'][tio.DATA].shape[-3:][d] for subject in batch]) for d in range(3)]\n",
    "    \n",
    "    # Apply padding to each image in the batch to match the largest dimensions\n",
    "    padded_subjects = []\n",
    "    for subject in batch:\n",
    "        subject_image = subject['swi_image'][tio.DATA]  # Get the image tensor\n",
    "        \n",
    "        # Calculate how much padding is needed for each dimension\n",
    "        padding = []\n",
    "        for max_dim, current_size in zip(max_dims, subject_image.shape[-3:]):\n",
    "            total_padding = max_dim - current_size\n",
    "            # Divide padding evenly across both sides\n",
    "            padding_before = total_padding // 2\n",
    "            padding_after = total_padding - padding_before  # Handle the case where the difference is odd\n",
    "            padding.extend([padding_before, padding_after])\n",
    "                \n",
    "        # Apply padding to the image\n",
    "        pad_transform = tio.Pad(padding)\n",
    "        padded_image = pad_transform(subject['swi_image'])\n",
    "        \n",
    "        # Create a new Subject with the padded image\n",
    "        padded_subject = tio.Subject(swi_image=tio.ScalarImage(tensor=padded_image[tio.DATA]))\n",
    "        padded_subjects.append(padded_subject)\n",
    "    \n",
    "    return padded_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "023a5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=6, collate_fn=pad_collate_fn, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e35164cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_for_prediction = model_for_prediction.to(device)\n",
    "\n",
    "patch_overlap = 4, 4, 4\n",
    "patch_size = 145,145,18\n",
    "inference_dataloader = test_dataloader\n",
    "logit_threshold = 0.5\n",
    "test_dir_location = test_dir\n",
    "prediction_dir_location = \"D:\\\\data_ETIS_781\\\\Training\\\\Predictions\\\\Test_Predictions\\\\SWI_Predictions\\\\Predictions_patients10_gamma5_thrombus05\"\n",
    "ground_truth_label_location = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Test\"\n",
    "\n",
    "whole_image_predictions = []\n",
    "\n",
    "for batch in inference_dataloader:\n",
    "    for subject in batch:\n",
    "        grid_sampler = tio.inference.GridSampler(subject, patch_size, patch_overlap)\n",
    "        patch_loader = tio.SubjectsLoader(grid_sampler, batch_size=10)\n",
    "        aggregator = tio.inference.GridAggregator(grid_sampler)\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            for patches_batch in patch_loader:\n",
    "                input_tensor = patches_batch[\"swi_image\"][tio.DATA].to(device)\n",
    "                locations = patches_batch[tio.LOCATION]\n",
    "                logits = model_for_prediction(input_tensor)[0]\n",
    "                logits = logits.cpu()\n",
    "                labels = logit_to_binary_mask(logits, threshold=logit_threshold)\n",
    "                aggregator.add_batch(labels, locations)\n",
    "        whole_prediction = aggregator.get_output_tensor().cpu()\n",
    "        whole_image_predictions.append(whole_prediction)\n",
    "original_size_predictions = restore_inference_original_size(whole_image_predictions, test_dir_location)\n",
    "\n",
    "for mask, filename in zip(original_size_predictions, os.listdir(test_dir_location)):\n",
    "    output_mask_name = \"_\".join(filename.split(\"_\")[:2]) + \"_Prediction\" + \".nii.gz\"\n",
    "    save_array_to_nifti1(np.array(mask), os.path.join(test_dir, filename), prediction_dir_location, output_mask_name)\n",
    "\n",
    "ground_truth_masks_list = load_prediction_masks(ground_truth_label_location)\n",
    "\n",
    "dice_metric = monai.metrics.DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "dice_score_list = [dice_metric(prediction.unsqueeze(0).unsqueeze(0), gt_mask.unsqueeze(0).unsqueeze(0)) for prediction, gt_mask in zip(prediction_list, ground_truth_masks_list)]\n",
    "print(f\"Mean Dice Score is {np.array(dice_score_list).flatten().mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7aea995",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list = load_prediction_masks(\"D:\\\\data_ETIS_781\\\\Training\\\\Predictions\\\\Test_Predictions\\\\SWI_Predictions\\\\Predictions_patients10_gamma5_thrombus05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8138247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_masks_list = load_prediction_masks(\"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3ee3986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_metric = monai.metrics.DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "dice_score_list = [dice_metric(prediction.unsqueeze(0).unsqueeze(0), gt_mask.unsqueeze(0).unsqueeze(0)) for prediction, gt_mask in zip(prediction_list, ground_truth_masks_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "550e9e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11288478"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dice_score_list).flatten().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7fd0c086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts, bins, patches = plt.hist(np.array(dice_score_list).flatten(), bins=10)\n",
    "\n",
    "for count, x in zip(counts, bins):\n",
    "    plt.text(x + 0.04, count, str(int(count)), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.xlabel(\"Dice Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e337e4",
   "metadata": {},
   "source": [
    "### Predict from whole images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "659087c6-76ae-44ab-b88f-1f2a46def0d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 512, 512, 24] at entry 0 and [1, 512, 512, 115] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m all_predictions_first \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicted_mask_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_for_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type(\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\u001b[43m}\u001b[49m)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type(\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\u001b[43m}\u001b[49m)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 512, 512, 24] at entry 0 and [1, 512, 512, 115] at entry 1"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "all_predictions_mean = []\n",
    "all_predictions_first = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, test_labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        predicted_mask_test = model_for_prediction(images)\n",
    "\n",
    "        predicted_mask_test_mean = predicted_mask_test.mean(dim=1)\n",
    "        predicted_mask_test_first = predicted_mask_test[:,0,:,:]\n",
    "\n",
    "        all_predictions_mean.append(predicted_mask_test_mean.cpu())\n",
    "        all_predictions_first.append(predicted_mask_test_first.cpu())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14820ab-ee9a-4089-ba50-ed63458882b7",
   "metadata": {},
   "source": [
    "## Testing ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcca993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
