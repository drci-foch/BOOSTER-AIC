{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "102557f9-7184-484b-bd0b-79795636e49b",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7759bce3-13cf-4cda-a6e8-1f01f86b305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchio as tio\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import monai\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b2901c-63ed-44ae-88bd-8bdbaacd7bb4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Filter out problematic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8537031-08db-41d9-8c64-d1fb376c5583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['06-10664-D0MR']\n",
      "['09-10683-D0MR']\n",
      "['09-10890-D0MR']\n",
      "['16-10232-D0MR']\n",
      "['21-10049-D0MR']\n",
      "['21-10049-D0MR']\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\SWI\"\n",
    "problem_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\Problem_Images\\\\SWI\"\n",
    "prev = []\n",
    "for file in os.listdir(source_dir):\n",
    "    number = file.split(\"_\")[1:2]\n",
    "    # if file.split(\"_\")[-1] == \"ph.nii.gz\":\n",
    "    #     ph_q = True\n",
    "    # else:\n",
    "    #     ph_q = False\n",
    "    if (number == prev):\n",
    "        print(number)\n",
    "        #os.rename(os.path.join(source_dir, file), os.path.join(problem_dir, file))\n",
    "    prev = number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "987fa1f8-78da-41d5-a7a2-da18b8b95351",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\TOF3D\"\n",
    "problem_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\Problem_Images\\\\TOF3D\"\n",
    "prev = []\n",
    "for file in os.listdir(source_dir):\n",
    "    number = file.split(\"_\")[1:2]\n",
    "    if \"_\".join(file.split(\"_\")[-2:]) == \"Eq_1.nii.gz\":\n",
    "        eq1_q = True\n",
    "    else:\n",
    "        eq1_q = False\n",
    "    if (number == prev) & (eq1_q):\n",
    "        os.rename(os.path.join(source_dir, file), os.path.join(problem_dir, file))\n",
    "    prev = number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc631a49-7746-496f-9fb5-2e925805c890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'16-10170-D0MR', '02-10871-D0MR', '07-10333-D0MR', '14-10034-D0MR', '21-10163-D0MR', '21-10135-D0MR', '18-10428-D0MR', '01-10221-D0MR', '14-10119-D0MR', '14-10239-D0MR', '06-10750-D0MR', '05-10410-D0MR', '30-10034-D0MR', '18-10183-D0MR', '14-10164-D0MR', '30-10085-D0MR', '06-10487-D0MR', '14-10269-D0MR', '14-10115-D0MR', '18-10542-D0MR', '18-10099-D0MR', '06-10516-D0MR', '09-10890-D0MR', '21-10158-D0MR', '02-10874-D0MR', '30-10091-D0MR', '16-10168-D0MR', '30-10092-D0MR', '30-10090-D0MR', '06-10778-D0MR', '14-10156-D0MR', '02-10555-D0MR', '17-10120-D0MR', '16-10025-D0MR', '14-10172-D0MR', '02-10878-D0MR', '14-10068-D0MR', '06-10769-D0MR', '02-10722-D0MR', '14-10153-D0MR', '14-10238-D0MR', '30-10082-D0MR', '30-10083-D0MR', '07-10335-D0MR', '14-10120-D0MR', '30-10076-D0MR', '18-10396-D0MR', '14-10123-D0MR', '18-10206-D0MR', '14-10173-D0MR', '14-10087-D0MR', '21-10049-D0MR', '30-10088-D0MR', '14-10166-D0MR', '04-10442-D0MR', '14-10125-D0MR', '30-10094-D0MR', '14-10243-D0MR', '09-10674-D0MR', '09-10683-D0MR', '09-10670-D0MR', '30-10068-D0MR', '02-10652-D0MR', '30-10089-D0MR', '02-10653-D0MR', '18-10315-D0MR', '14-10171-D0MR', '04-10209-D0MR', '05-10383-D0MR', '30-10084-D0MR', '18-10037-D0MR', '11-10071-D0MR', '16-10117-D0MR', '18-10150-D0MR', '14-10086-D0MR', '30-10070-D0MR'}\n"
     ]
    }
   ],
   "source": [
    "swi_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\SWI\"\n",
    "mask_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\MASK\"\n",
    "\n",
    "swi_numbers = [file.split(\"_\")[1:2][0] for file in os.listdir(swi_dir)]\n",
    "mask_numbers = [file.split(\"_\")[1:2][0] for file in os.listdir(mask_dir)]\n",
    "\n",
    "diff = set(mask_numbers) - set(swi_numbers)\n",
    "\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "473d4408-8c01-425e-80ba-9a1b0bb3f0c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2018-104_16-10170-D0MR_22_AX_T2_EG.nii.gz\n",
      "Processed 2018-104_02-10871-D0MR_6_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_07-10333-D0MR_20_SWI_Images.nii.gz\n",
      "Processed 2018-104_14-10034-D0MR_5_Ax_T2_.nii.gz\n",
      "Processed 2018-104_21-10163-D0MR_401_cs_T2_FFE.nii.gz\n",
      "Processed 2018-104_21-10135-D0MR_5_Ax_T2_.nii.gz\n",
      "Processed 2018-104_18-10428-D0MR_11_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_01-10221-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_14-10119-D0MR_16_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10239-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_06-10750-D0MR_8_AX_T2_EG_STD.nii.gz\n",
      "Processed 2018-104_05-10410-D0MR_12_t2_fl2d_tra_4mm_hemo_te_25.nii.gz\n",
      "Processed 2018-104_30-10034-D0MR_8_t2_fl2d_ax.nii.gz\n",
      "Processed 2018-104_18-10183-D0MR_12_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10164-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10085-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_06-10487-D0MR_9_AX_T2_EG_STD.nii.gz\n",
      "Processed 2018-104_14-10269-D0MR_16_AX_T2_.nii.gz\n",
      "Processed 2018-104_14-10115-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_18-10542-D0MR_8_AXIAL_T2_EG.nii.gz\n",
      "Processed 2018-104_18-10099-D0MR_5_Ax_T2_4mm.nii.gz\n",
      "Processed 2018-104_06-10516-D0MR_502_eAX_T2_.nii.gz\n",
      "Processed 2018-104_09-10890-D0MR_501_SWI_AVC.nii.gz\n",
      "Processed 2018-104_09-10890-D0MR_501_SWI_AVC_ph.nii.gz\n",
      "Processed 2018-104_21-10158-D0MR_401_cs_T2_FFE.nii.gz\n",
      "Processed 2018-104_02-10874-D0MR_6_Ax_eSWAN_2017.nii.gz\n",
      "Processed 2018-104_30-10091-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_16-10168-D0MR_15_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10092-D0MR_9_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10090-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_06-10778-D0MR_4_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10156-D0MR_6_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_02-10555-D0MR_5_3D_eSWAN_RAPIDE.nii.gz\n",
      "Processed 2018-104_17-10120-D0MR_6_Ax_T2_.nii.gz\n",
      "Processed 2018-104_16-10025-D0MR_12_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10172-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_02-10878-D0MR_5_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10068-D0MR_5_Ax_T2_.nii.gz\n",
      "Processed 2018-104_06-10769-D0MR_13_AX_T2_EG_STD.nii.gz\n",
      "Processed 2018-104_02-10722-D0MR_6_Ax_3D_SWAN+CARTO.nii.gz\n",
      "Processed 2018-104_14-10153-D0MR_5_3D_Ax_SWAN_4mm.nii.gz\n",
      "Processed 2018-104_14-10238-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10082-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10083-D0MR_13_SWI_Images.nii.gz\n",
      "Processed 2018-104_07-10335-D0MR_6_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10120-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10076-D0MR_8_t2_fl2d_ax.nii.gz\n",
      "Processed 2018-104_18-10396-D0MR_12_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10123-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_18-10206-D0MR_11_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10173-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_14-10087-D0MR_5_Ax_SWAN_2.4MM.nii.gz\n",
      "Processed 2018-104_21-10049-D0MR_401_SWIp.nii.gz\n",
      "Processed 2018-104_21-10049-D0MR_401_SWIp_Eq_1.nii.gz\n",
      "Processed 2018-104_21-10049-D0MR_401_SWIp_ph.nii.gz\n",
      "Processed 2018-104_30-10088-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_14-10166-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_04-10442-D0MR_14_T2_EG_TRA.nii.gz\n",
      "Processed 2018-104_14-10125-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10094-D0MR_4_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10243-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_09-10674-D0MR_5_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_09-10683-D0MR_501_SWI_AVC.nii.gz\n",
      "Processed 2018-104_09-10683-D0MR_501_SWI_AVC_ph.nii.gz\n",
      "Processed 2018-104_09-10670-D0MR_502_AXIAL_SWI.nii.gz\n",
      "Processed 2018-104_30-10068-D0MR_8_t2_fl2d_ax.nii.gz\n",
      "Processed 2018-104_02-10652-D0MR_5_Ax_SWAN.nii.gz\n",
      "Processed 2018-104_30-10089-D0MR_15_SWI_Images.nii.gz\n",
      "Processed 2018-104_02-10653-D0MR_13_AX_T2_EG.nii.gz\n",
      "Processed 2018-104_18-10315-D0MR_11_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10171-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_04-10209-D0MR_5_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_05-10383-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10084-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_18-10037-D0MR_501_T2_FFE_CS.nii.gz\n",
      "Processed 2018-104_11-10071-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_16-10117-D0MR_13_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_18-10150-D0MR_14_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10086-D0MR_6_3D_Ax_SWAN.nii.gz\n",
      "Processed 2018-104_30-10070-D0MR_8_t2_fl2d_ax.nii.gz\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"E:\\\\Data_ETIS\\\\THROMBMICS-ALARMS_20240531\"\n",
    "target_dir = \"E:\\\\Data_ETIS\\\\Temp\"\n",
    "\n",
    "for number in list(diff):\n",
    "    for directory in glob.glob(os.path.join(source_dir, \"2018-104_\"+ number, \"T2star_*\")):\n",
    "        for nii_file in os.listdir(directory):\n",
    "            os.rename(os.path.join(directory, nii_file), os.path.join(target_dir, nii_file))\n",
    "            print(\"Processed \"+ nii_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b611b762-ea53-415a-af59-a47a1073ae11",
   "metadata": {},
   "source": [
    "## Separate Test Batch of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85ffd9f8-2f8d-4b13-833a-02053ebea35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "thrombus_mask_train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_labels\\\\MASK_Train\"\n",
    "thrombus_mask_test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Test\"\n",
    "thrombus_mask_val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_labels\\\\MASK_Val\"\n",
    "foreground_mask_train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_labels\\\\MASK_Foreground_Train\"\n",
    "foreground_mask_test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Foreground_Test\"\n",
    "foreground_mask_val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_labels\\\\MASK_Foreground_Val\"\n",
    "swi_train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_dataset\\\\SWI_Train\"\n",
    "swi_test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_dataset\\\\SWI_Test\"\n",
    "swi_val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_dataset\\\\SWI_Val\"\n",
    "tof_train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_dataset\\\\TOF3D_Train\"\n",
    "tof_test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_dataset\\\\TOF3D_Test\"\n",
    "tof_val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_dataset\\\\TOF3D_Val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15cfda5e-2785-4836-ae83-889a9c3680ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_image_batch(thrombus_mask_source, thrombus_mask_destination, foreground_mask_source, foreground_mask_destination, swi_source, swi_destination, tof_source, tof_destination, batch_size, seed_value=777):\n",
    "    # Separate four source folders, thrombus mask(labels) , brain foreground masks with thrombus, swi images, tof images into four other destination folders (e.g. validation or test),\n",
    "    # sending the specified number of images selected randomly.\n",
    "    random.seed(seed_value)\n",
    "    batch_indexes = random.sample(range(len(os.listdir(thrombus_mask_source))), batch_size)\n",
    "\n",
    "    thrombus_mask_file_list = [os.listdir(thrombus_mask_source)[index] for index in batch_indexes]\n",
    "    for file in thrombus_mask_file_list:\n",
    "        os.rename(os.path.join(thrombus_mask_source, file), os.path.join(thrombus_mask_destination, file))\n",
    "\n",
    "    foreground_mask_file_list = [os.listdir(foreground_mask_source)[index] for index in batch_indexes]\n",
    "    for file in foreground_mask_file_list:\n",
    "        os.rename(os.path.join(foreground_mask_source, file), os.path.join(foreground_mask_destination, file))\n",
    "    \n",
    "    swi_file_list = [os.listdir(swi_source)[index] for index in batch_indexes]\n",
    "    for file in swi_file_list:\n",
    "        os.rename(os.path.join(swi_source, file), os.path.join(swi_destination, file))\n",
    "\n",
    "    tof_file_list = [os.listdir(tof_source)[index] for index in batch_indexes]\n",
    "    for file in tof_file_list:\n",
    "        os.rename(os.path.join(tof_source, file), os.path.join(tof_destination, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e1d3c-9c23-403f-8526-00efb1ca3d63",
   "metadata": {},
   "source": [
    "Separate test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "626d9491-7bfb-4bd3-9313-97dbe1b65efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_image_batch(thrombus_mask_train_dir, thrombus_mask_test_dir, foreground_mask_train_dir, foreground_mask_test_dir, swi_train_dir, swi_test_dir, tof_train_dir, tof_test_dir, 100, seed_value=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2501cdcb-4fc7-469c-bfe0-68f0386c28d6",
   "metadata": {},
   "source": [
    "Separate validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9ceb8cf-3ec5-480f-89c3-db6377789c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_image_batch(thrombus_mask_train_dir, thrombus_mask_val_dir, foreground_mask_train_dir, foreground_mask_val_dir, swi_train_dir, swi_val_dir, tof_train_dir, tof_val_dir, 181, seed_value=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192edc50-ce79-4d19-92b1-9c341d8a235c",
   "metadata": {},
   "source": [
    "Clear out the training folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a6f313a-6428-4483-930a-0dd5d31811e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_training_folders(thrombus_mask_train_dir, thrombus_mask_test_dir, thrombus_mask_val_dir, foreground_mask_train_dir, foreground_mask_test_dir, foreground_mask_val_dir, swi_train_dir, swi_test_dir, swi_val_dir, tof_train_dir, tof_test_dir, tof_val_dir):\n",
    "    # Remove files from training, validation and test folders of labels, foreground masks, swi images and tof images.\n",
    "    folder_list = [thrombus_mask_train_dir, thrombus_mask_test_dir, thrombus_mask_val_dir, foreground_mask_train_dir, foreground_mask_test_dir, foreground_mask_val_dir, swi_train_dir, swi_test_dir, swi_val_dir, tof_train_dir, tof_test_dir, tof_val_dir]\n",
    "    for folders in folder_list:\n",
    "        for file in os.listdir(folders):\n",
    "            os.remove(os.path.join(folders, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc04a0dc-cf1a-4b8c-af61-c0d3111a7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_training_folders(thrombus_mask_train_dir, thrombus_mask_test_dir, thrombus_mask_val_dir, foreground_mask_train_dir, foreground_mask_test_dir, foreground_mask_val_dir, swi_train_dir, swi_test_dir, swi_val_dir, tof_train_dir, tof_test_dir, tof_val_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f50055-f8bf-4c98-be7f-72b256862585",
   "metadata": {},
   "source": [
    "Fill training folders from processed images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d97d0b10-438e-4df8-a04c-3ae0c5b33db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_training_folders(source_dir, thrombus_mask_train_dir, swi_train_dir, tof_train_dir):\n",
    "    # Send images from a source folder containing MASK, SWI and TOF3D folders to the training folders.\n",
    "    for folders in os.listdir(source_dir):\n",
    "        if (folders.split(\"_\")[0] == \"MASK\") | (folders == \"MASK\"):\n",
    "            for files in os.listdir(os.path.join(source_dir, folders)):\n",
    "                os.rename(os.path.join(source_dir, folders, files), os.path.join(thrombus_mask_train_dir,files))\n",
    "        elif folders.split(\"_\")[0] == \"SWI\":\n",
    "            for files in os.listdir(os.path.join(source_dir, folders)):\n",
    "                os.rename(os.path.join(source_dir, folders, files), os.path.join(swi_train_dir,files))\n",
    "        elif folders.split(\"_\")[0] == \"TOF3D\":\n",
    "            for files in os.listdir(os.path.join(source_dir, folders)):\n",
    "                os.rename(os.path.join(source_dir, folders, files), os.path.join(tof_train_dir,files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "245da8d3-712e-4e64-ae11-09e365713ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"D:\\\\data_ETIS_781\\\\Resized\"\n",
    "\n",
    "fill_training_folders(source_dir, thrombus_mask_train_dir, swi_train_dir, tof_train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7944ba3-9b36-425b-a661-8cbbfd62772b",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "870e295a-7037-4fe4-9bfc-9e00b95faaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_array_to_nifti1(array, original_img, destination_path, output_name):\n",
    "    # Transform the array to a nifti image which requires the affine of the original image.\n",
    "    if isinstance(original_img, nib.Nifti1Image) :\n",
    "        processed_img = nib.Nifti1Image(array, original_img.affine)\n",
    "    else:\n",
    "        processed_img = nib.Nifti1Image(array, nib.load(original_img).affine)\n",
    "    \n",
    "    nib.save(processed_img, os.path.join(destination_path, output_name))\n",
    "\n",
    "def remove_padding_from_tensor(tensor, original_dims):\n",
    "    # Apply the padding removal function to the tensor to restore the original dimensions\n",
    "    current_dims = tensor.shape[-len(original_dims):]\n",
    "    resized_tensor = tensor\n",
    "    \n",
    "    for dim, (original_size, current_size) in enumerate(zip(original_dims, current_dims), start=-len(original_dims)):\n",
    "        total_padding = current_size - original_size\n",
    "        padding_before = total_padding // 2\n",
    "        \n",
    "        resized_tensor = torch.narrow(resized_tensor, dim, padding_before, original_size)\n",
    "    return resized_tensor\n",
    "\n",
    "def logit_to_binary_mask(tensor, threshold=0.5):\n",
    "    # Transform a tensor of logits into a binary mask according to the specified probability threshold.\n",
    "    mask_tensor = torch.sigmoid(tensor)\n",
    "\n",
    "    return (mask_tensor >= threshold).float()\n",
    "\n",
    "def restore_inference_original_size (prediction_list, original_img_dir):\n",
    "    return [torch.squeeze(\n",
    "        remove_padding_from_tensor(prediction, nib.load(os.path.join(original_img_dir, original_file)).shape)\n",
    "        )\n",
    "        for prediction, original_file in zip(prediction_list, os.listdir(original_img_dir))\n",
    "        ]\n",
    "\n",
    "def load_prediction_masks (mask_dir):\n",
    "    return [torch.tensor(nib.load(os.path.join(mask_dir, mask)).get_fdata()) for mask in os.listdir(mask_dir) if (mask.endswith(\".nii.gz\"))]\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, filepath):\n",
    "    # Saves a checkpoint of a PyTorch model.\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    torch.save(checkpoint, filepath)\n",
    "\n",
    "def get_image_set_breakdown (train_dir, val_dir, test_dir):\n",
    "    # Returns a list of image number included in training, validation and test set for future reference.\n",
    "    train_list = [\"_\".join(img_filename.split(\"_\")[:2]) for img_filename in os.listdir(train_dir) if (img_filename.endswith(\".nii.gz\"))]\n",
    "    val_list = [\"_\".join(img_filename.split(\"_\")[:2]) for img_filename in os.listdir(val_dir) if (img_filename.endswith(\".nii.gz\"))]\n",
    "    test_list = [\"_\".join(img_filename.split(\"_\")[:2]) for img_filename in os.listdir(test_dir) if (img_filename.endswith(\".nii.gz\"))]\n",
    "\n",
    "    return train_list, val_list, test_list\n",
    "\n",
    "def save_model_params (save_location, train_swi_dir, val_swi_dir, test_swi_dir,\n",
    "                       patches_per_image, patch_size, queue_length, batch_size,\n",
    "                       model_architecture, channels,\n",
    "                       model_loss, model_optimizer,\n",
    "                       model_notes=None, loss_notes=None, optimizer_notes=None, training_epochs=None):\n",
    "    \n",
    "    train_list, val_list, test_list = get_image_set_breakdown (train_swi_dir, val_swi_dir, test_swi_dir)\n",
    "    \n",
    "    model_params = {\"train_total\":len(train_list), \"validation_total\":len(val_list), \"test_total\": len(test_list), \"patches_per_image\":patches_per_image,\n",
    "                \"patch_size\":patch_size, \"queue_length\":queue_length, \"batch_size\":batch_size,\n",
    "                \"model_architecture\":model_architecture, \"channels\":channels, \"model_notes\":model_notes,\n",
    "                \"model_loss\":model_loss, \"loss_notes\":loss_notes,\n",
    "                \"model_optimizer\":model_optimizer, \"optimizer_notes\":optimizer_notes,\n",
    "                \"training_epochs\":training_epochs,\n",
    "                \"train_image_numbers\":train_list, \"validation_image_numbers\":val_list, \"test_image_numbers\":test_list\n",
    "                }\n",
    "    \n",
    "    with open(save_location, \"w\") as f:\n",
    "        json.dump(model_params, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76050939-e922-464c-ae1d-addada7e527d",
   "metadata": {},
   "source": [
    "## 3D Segmentation Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f20d5-1181-44bc-91c2-dd43cd2a574d",
   "metadata": {},
   "source": [
    "### Use the SubjectsDataset class from torchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe9e0e0-5ee9-4620-8b7c-f4ecfd5a49be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighToleranceSubject(tio.Subject):\n",
    "    # A custom instance of Subject with higher tolerance in attribute checking.\n",
    "    def check_consistent_attribute(self, *args, **kwargs) -> None:\n",
    "        kwargs['relative_tolerance'] = 1e-3\n",
    "        kwargs['absolute_tolerance'] = 1e-3\n",
    "        return super().check_consistent_attribute(*args, **kwargs)\n",
    "\n",
    "def load_subjectsdataset_1channel (swi_dir, thrombus_labels_dir, foreground_labels_dir, **kwargs):\n",
    "    subjects_list = []\n",
    "    swi_list = os.listdir(swi_dir)\n",
    "    thrombus_labels_list = os.listdir(thrombus_labels_dir)\n",
    "    foreground_labels_list = os.listdir(foreground_labels_dir)\n",
    "    \n",
    "    if len(swi_list) != len(thrombus_labels_list) != len(foreground_labels_list):\n",
    "        print(\"Mismatch in sample numbers\")\n",
    "    \n",
    "    for swi_file, thrombus_label_file, foreground_label_file in zip(swi_list, thrombus_labels_list, foreground_labels_list):\n",
    "        subject = HighToleranceSubject(\n",
    "            swi_image=tio.ScalarImage(os.path.join(swi_dir, swi_file)),\n",
    "            thrombus_label = tio.LabelMap(os.path.join(thrombus_labels_dir, thrombus_label_file)),\n",
    "            foreground_label = tio.LabelMap(os.path.join(foreground_labels_dir, foreground_label_file)),\n",
    "            subject_number = \"_\".join(swi_file.split(\"_\")[:2])\n",
    "        )\n",
    "        subjects_list.append(subject)\n",
    "    \n",
    "    return tio.SubjectsDataset(subjects_list, **kwargs)\n",
    "\n",
    "def load_subjectsdataset_2channel (swi_dir, tof_dir, thrombus_labels_dir, foreground_labels_dir, **kwargs):\n",
    "    subjects_list = []\n",
    "    swi_list = os.listdir(swi_dir)\n",
    "    tof_list = os.listdir(tof_dir)\n",
    "    thrombus_labels_list = os.listdir(thrombus_labels_dir)\n",
    "    foreground_labels_list = os.listdir(foreground_labels_dir)\n",
    "    \n",
    "    if len(swi_list) != len(tof_list) != len(thrombus_labels_list) != len(foreground_labels_list):\n",
    "        print(\"Mismatch in sample numbers\")\n",
    "    \n",
    "    for swi_file, tof_file, thrombus_label_file, foreground_label_file in zip(swi_list, tof_list, thrombus_labels_list, foreground_labels_list):\n",
    "        subject = HighToleranceSubject(\n",
    "            swi_image=tio.ScalarImage(os.path.join(swi_dir, swi_file)),\n",
    "            tof_image=tio.ScalarImage(os.path.join(tof_dir, tof_file)),\n",
    "            thrombus_label = tio.LabelMap(os.path.join(thrombus_labels_dir, thrombus_label_file)),\n",
    "            foreground_label = tio.LabelMap(os.path.join(foreground_labels_dir, foreground_label_file)),\n",
    "            subject_number = \"_\".join(swi_file.split(\"_\")[:2])\n",
    "        )\n",
    "        subjects_list.append(subject)\n",
    "    \n",
    "    return tio.SubjectsDataset(subjects_list, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48623be8-971b-4b85-b794-76cc963d23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_swi_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_dataset\\\\SWI_Train\"\n",
    "train_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_labels\\\\MASK_Train\"\n",
    "train_foreground_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_labels\\MASK_Foreground_Train\"\n",
    "val_swi_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_dataset\\\\SWI_Val\"\n",
    "val_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_labels\\\\MASK_Val\"\n",
    "val_foreground_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_labels\\\\MASK_Foreground_Val\"\n",
    "test_swi_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_dataset\\\\SWI_Test\"\n",
    "test_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Test\"\n",
    "test_foreground_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Foreground_Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "930bea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_params (save_location, train_swi_dir, val_swi_dir, test_swi_dir,\n",
    "                       patches_per_image, patch_size, queue_length, batch_size,\n",
    "                       model_architecture, channels,\n",
    "                       model_loss, model_optimizer,\n",
    "                       model_notes=None, loss_notes=None, optimizer_notes=None, training_epochs=None):\n",
    "    \n",
    "    train_list, val_list, test_list = get_image_set_breakdown (train_swi_dir, val_swi_dir, test_swi_dir)\n",
    "    \n",
    "    model_params = {\"train_total\":len(train_list), \"validation_total\":len(val_list), \"test_total\": len(test_list), \"patches_per_image\":patches_per_image,\n",
    "                \"patch_size\":patch_size, \"queue_length\":queue_length, \"batch_size\":batch_size,\n",
    "                \"model_architecture\":model_architecture, \"channels\":channels, \"model_notes\":model_notes,\n",
    "                \"model_loss\":model_loss, \"loss_notes\":loss_notes,\n",
    "                \"model_optimizer\":model_optimizer, \"optimizer_notes\":optimizer_notes,\n",
    "                \"training_epochs\":training_epochs,\n",
    "                \"train_image_numbers\":train_list, \"validation_image_numbers\":val_list, \"test_image_numbers\":test_list\n",
    "                }\n",
    "    \n",
    "    with open(save_location, \"w\") as f:\n",
    "        json.dump(model_params, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "913d27eb-e3b9-436c-bb91-6501c7e302f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_subjectsdataset_1channel(train_swi_dir, train_label_dir, train_foreground_label_dir)\n",
    "val_dataset = load_subjectsdataset_1channel(val_swi_dir, val_label_dir, val_foreground_label_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22be69e4-08b9-46b1-8420-dbddd5c2f88b",
   "metadata": {},
   "source": [
    "### Setup Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce12750e-23cf-4046-82f4-ec96e8c72e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = tio.data.LabelSampler(patch_size=(145,145,18), label_name=\"foreground_label\", label_probabilities={0: 0, 1: 0.8, 2: 0.2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33359195",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue_length = 3500\n",
    "samples_per_volume = 25\n",
    "\n",
    "train_patches_queue = tio.Queue(train_dataset, queue_length, samples_per_volume, train_sampler, num_workers=0)\n",
    "val_patches_queue = tio.Queue(val_dataset, queue_length, samples_per_volume, train_sampler, num_workers=0)\n",
    "\n",
    "train_patches_loader = tio.SubjectsLoader(train_patches_queue, batch_size=9, num_workers=0)\n",
    "val_patches_loader = tio.SubjectsLoader(val_patches_queue, batch_size=9, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d998e6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14.8 GiB'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tio.Queue.get_max_memory_pretty(train_patches_queue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c693769",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df1b33e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNetPlusPlus features: (32, 32, 64, 128, 256, 32).\n"
     ]
    }
   ],
   "source": [
    "model = monai.networks.nets.BasicUNetPlusPlus(spatial_dims=3, in_channels=1, out_channels=1, features=(32,32,64,128,256,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcc47e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_loss = monai.losses.FocalLoss(gamma=8, alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9eeb88ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce1514b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model (model, loss, optimizer, train_patches_loader, val_patches_loader, num_epochs=10, save_checkpoint_flag=False, checkpoint_location=None, display_loss=False):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    if display_loss:\n",
    "        train_loss_history = []\n",
    "        val_loss_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss_value = 0\n",
    "        for patches_batch in tqdm.tqdm(train_patches_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\"):\n",
    "            images = patches_batch[\"swi_image\"][tio.DATA]\n",
    "            gt_masks = patches_batch[\"thrombus_label\"][tio.DATA]\n",
    "            images, gt_masks = images.to(device), gt_masks.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predicted_mask = model(images)[0]\n",
    "            train_loss = loss(predicted_mask, gt_masks)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_value += train_loss.item()\n",
    "        \n",
    "        train_loss_value /= len(train_patches_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss_value:.8f}\")\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss_value = 0\n",
    "        with torch.no_grad():\n",
    "            for patches_batch in tqdm.tqdm(val_patches_loader, desc=f\"Validating Epoch {epoch+1}/{num_epochs}\"):\n",
    "                images = patches_batch[\"swi_image\"][tio.DATA]\n",
    "                gt_masks = patches_batch[\"thrombus_label\"][tio.DATA]\n",
    "                images, gt_masks = images.to(device), gt_masks.to(device)\n",
    "                \n",
    "                predicted_mask = model(images)[0]\n",
    "                val_loss = loss(predicted_mask, gt_masks)\n",
    "                val_loss_value += val_loss.item()\n",
    "\n",
    "        val_loss_value /= len(val_patches_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss_value:.8f}\")\n",
    "\n",
    "        if display_loss:\n",
    "            train_loss_history.append(train_loss_value)\n",
    "            val_loss_history.append(val_loss_value)\n",
    "            fig, ax = plt.subplots(figsize=(4, 3))\n",
    "            ax.plot(range(1, len(train_loss_value) + 1), train_loss_value, label=\"Train Loss\")\n",
    "            ax.plot(range(1, len(val_loss_value) + 1), val_loss_value, label=\"Validation Loss\")\n",
    "\n",
    "            ax.set_xlabel(\"Epoch\")\n",
    "            ax.set_ylabel(\"Loss\")\n",
    "            ax.set_title(\"Loss history\")\n",
    "            ax.ticklabel_format(axis=\"y\", style=\"scientific\", scilimits=(0,0))\n",
    "            ax.legend()\n",
    "            plt.show()\n",
    "        \n",
    "        if save_checkpoint_flag:\n",
    "            save_checkpoint(model, optimizer, epoch, loss, checkpoint_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3a28e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/10:   0%|          | 0/1614 [00:00<?, ?it/s]c:\\Users\\wijflo\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torchio\\data\\image.py:251: UserWarning: Using TorchIO images without a torchio.SubjectsLoader in PyTorch >= 2.3 might have unexpected consequences, e.g., the collated batches will be instances of torchio.Subject with 5D images. Replace your PyTorch DataLoader with a torchio.SubjectsLoader so that the collated batch becomes a dictionary, as expected. See https://github.com/fepegar/torchio/issues/1179 for more context about this issue.\n",
      "  warnings.warn(message, stacklevel=1)\n",
      "Training Epoch 1/10:   2%|▏         | 30/1614 [11:10<9:50:25, 22.36s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfocal_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_patches_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_patches_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_checkpoint_flag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdata_ETIS_781\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mTraining\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mCheckpoints\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mSWI_1channel\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m581x25_gamma8\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mtrain_581x25_gamma8_checkpoint.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 21\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, loss, optimizer, train_patches_loader, val_patches_loader, num_epochs, save_checkpoint_flag, checkpoint_location, display_loss)\u001b[0m\n\u001b[0;32m     19\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     20\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 21\u001b[0m     train_loss_value \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m train_loss_value \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_patches_loader)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Training Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.8f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model, focal_loss, optimizer, train_patches_loader, val_patches_loader, num_epochs=10, save_checkpoint_flag=True, checkpoint_location=\"D:\\\\data_ETIS_781\\\\Training\\\\Checkpoints\\\\model\\\\SWI_1channel\\\\581x25_gamma8\\\\train_581x25_gamma8_checkpoint.pth\", display_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59fd10c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_params (\"D:\\\\data_ETIS_781\\\\Training\\\\Checkpoints\\\\model\\\\SWI_1channel\\\\581x25_gamma8\\\\model_581x25_gamma8_params.json\", train_swi_dir, val_swi_dir, test_swi_dir,\n",
    "                       25, (145,145,18), 7000, 10,\n",
    "                       \"Monai BasicUNetPlusPlus\", [\"SWI\"],\n",
    "                       \"Monai Focal Loss\", \"Adam\",\n",
    "                       model_notes={\"features\":(32,32,64,128,256,32)}, loss_notes={\"gamma\":8,\"alpha\":0.75}, optimizer_notes={\"learning_rate\":0.001}, training_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a3d5d1-8a9b-46bf-ba0b-a40014a7d8ec",
   "metadata": {},
   "source": [
    "## Load model and predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b6f014",
   "metadata": {},
   "source": [
    "### Predict from patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7206679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNetPlusPlus features: (32, 32, 64, 128, 256, 32).\n"
     ]
    }
   ],
   "source": [
    "model_for_prediction = monai.networks.nets.BasicUNetPlusPlus(spatial_dims=3, in_channels=1, out_channels=1, features=(32,32,64,128,256,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6304d2f-4cb8-4eea-9d90-a50fc1206ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer_for_prediction = torch.optim.Adam(model_for_prediction.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05bb09cc-90dc-4a06-ba88-90161cf6916c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wijflo\\AppData\\Local\\Temp\\ipykernel_15468\\205849153.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_for_prediction_checkpoint = torch.load(\"D:\\\\data_ETIS_781\\\\Training\\\\Checkpoints\\\\model\\\\SWI_1channel\\\\581x25_gamma2\\\\train_581x25_gamma2_checkpoint.pth\")\n"
     ]
    }
   ],
   "source": [
    "model_for_prediction_checkpoint = torch.load(\"D:\\\\data_ETIS_781\\\\Training\\\\Checkpoints\\\\model\\\\SWI_1channel\\\\581x25_gamma2\\\\train_581x25_gamma2_checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24ef5435-17bc-4791-92aa-61bb462af246",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_prediction.load_state_dict(model_for_prediction_checkpoint[\"model_state_dict\"])\n",
    "optimizer_for_prediction.load_state_dict(model_for_prediction_checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac5185ba-212b-4a01-8807-ee56a4a2ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_dataset\\\\SWI_Train\"\n",
    "train_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_labels\\\\MASK_Train\"\n",
    "train_foreground_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_labels\\MASK_Foreground_Train\"\n",
    "val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_dataset\\\\SWI_Val\"\n",
    "val_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_labels\\\\MASK_Val\"\n",
    "val_foreground_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_labels\\\\MASK_Foreground_Val\"\n",
    "test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_dataset\\\\SWI_Test\"\n",
    "test_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Test\"\n",
    "test_foreground_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Foreground_Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "554c9d05-434f-4d38-ae29-16face140bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = load_subjectsdataset_1channel (train_dir, train_label_dir, train_foreground_label_dir)\n",
    "#val_dataset = load_subjectsdataset_1channel (val_dir, val_label_dir, val_foreground_label_dir)\n",
    "test_dataset = load_subjectsdataset_1channel (test_dir, test_label_dir, test_foreground_label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff07c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate_fn(batch):\n",
    "    # Collate function to ensure batches have the same size, that is the size of the largest image in the batch.\n",
    "    # Find the max shape in each dimension from the batch\n",
    "    max_dims = [max([subject['swi_image'][tio.DATA].shape[-3:][d] for subject in batch]) for d in range(3)]\n",
    "    \n",
    "    # Apply padding to each image in the batch to match the largest dimensions\n",
    "    padded_subjects = []\n",
    "    for subject in batch:\n",
    "        subject_image = subject['swi_image'][tio.DATA]  # Get the image tensor\n",
    "        \n",
    "        # Calculate how much padding is needed for each dimension\n",
    "        padding = []\n",
    "        for max_dim, current_size in zip(max_dims, subject_image.shape[-3:]):\n",
    "            total_padding = max_dim - current_size\n",
    "            # Divide padding evenly across both sides\n",
    "            padding_before = total_padding // 2\n",
    "            padding_after = total_padding - padding_before  # Handle the case where the difference is odd\n",
    "            padding.extend([padding_before, padding_after])\n",
    "                \n",
    "        # Apply padding to the image\n",
    "        pad_transform = tio.Pad(padding)\n",
    "        padded_image = pad_transform(subject['swi_image'])\n",
    "        \n",
    "        # Create a new Subject with the padded image\n",
    "        padded_subject = tio.Subject(swi_image=tio.ScalarImage(tensor=padded_image[tio.DATA]))\n",
    "        padded_subjects.append(padded_subject)\n",
    "    \n",
    "    return padded_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "023a5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=6, collate_fn=pad_collate_fn, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85a6a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference (inference_dataloader, model_for_prediction, patch_size, patch_overlap, inference_dir_location, return_logits=True, patch_loader_batchsize=10, logit_threshold=0.5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model_for_prediction = model_for_prediction.to(device)\n",
    "\n",
    "    whole_image_predictions = []\n",
    "\n",
    "    for batch in inference_dataloader:\n",
    "        for subject in batch:\n",
    "            grid_sampler = tio.inference.GridSampler(subject, patch_size, patch_overlap)\n",
    "            patch_loader = tio.SubjectsLoader(grid_sampler, batch_size=patch_loader_batchsize)\n",
    "            aggregator = tio.inference.GridAggregator(grid_sampler)\n",
    "            \n",
    "            with torch.no_grad(): \n",
    "                for patches_batch in tqdm.tqdm(patch_loader, desc=\"Running Inference\"):\n",
    "                    input_tensor = patches_batch[\"swi_image\"][tio.DATA].to(device)\n",
    "                    locations = patches_batch[tio.LOCATION]\n",
    "                    logits = model_for_prediction(input_tensor)[0]\n",
    "                    logits = logits.cpu()\n",
    "                    if return_logits == False:\n",
    "                        labels = logit_to_binary_mask(logits, threshold=logit_threshold)\n",
    "                        aggregator.add_batch(labels, locations)\n",
    "                    else:\n",
    "                        aggregator.add_batch(logits, locations)\n",
    "            whole_prediction = aggregator.get_output_tensor().cpu()\n",
    "            whole_image_predictions.append(whole_prediction)\n",
    "    return restore_inference_original_size(whole_image_predictions, inference_dir_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82465c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions (predictions_list, save_destination, filename_source_dir):\n",
    "    if not os.path.exists(save_destination):\n",
    "        os.makedirs(save_destination)\n",
    "        print(f\"Folder created at {save_destination}\")\n",
    "    else:\n",
    "        if os.listdir(save_destination):\n",
    "            print(f\"Error: Save location at {save_destination} is not empty.\")\n",
    "            sys.exit(1)\n",
    "            \n",
    "    for mask, filename in zip(predictions_list, os.listdir(filename_source_dir)):\n",
    "        output_mask_name = \"_\".join(filename.split(\"_\")[:2]) + \"_Prediction\" + \".nii.gz\"\n",
    "        save_array_to_nifti1(np.array(mask), os.path.join(filename_source_dir, filename), save_destination, output_mask_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e83126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dice_metric (prediction_list, ground_truth_masks_list):\n",
    "    dice_metric = monai.metrics.DiceMetric(include_background=True, reduction=\"mean\", get_not_nans=False)\n",
    "    dice_score_list = np.array(\n",
    "        [dice_metric(prediction.unsqueeze(0).unsqueeze(0), gt_mask.unsqueeze(0).unsqueeze(0))\n",
    "         for prediction, gt_mask in zip(prediction_list, ground_truth_masks_list)]\n",
    "        ).flatten()\n",
    "    print(f\"Mean Dice Score is {dice_score_list.mean()}\")\n",
    "    return dice_score_list\n",
    "\n",
    "def compute_sensitivity_metric (prediction_list, ground_truth_masks_list):\n",
    "    intersection_list = np.array(\n",
    "        [((prediction * gt_mask).sum()/gt_mask.sum()) for prediction, gt_mask in zip(prediction_list, ground_truth_masks_list)]\n",
    "    ).flatten()\n",
    "    print(f\"Mean Sensitivity is {intersection_list.mean()}\")\n",
    "    return intersection_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "448af008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wijflo\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\torchio\\data\\image.py:251: UserWarning: Using TorchIO images without a torchio.SubjectsLoader in PyTorch >= 2.3 might have unexpected consequences, e.g., the collated batches will be instances of torchio.Subject with 5D images. Replace your PyTorch DataLoader with a torchio.SubjectsLoader so that the collated batch becomes a dictionary, as expected. See https://github.com/fepegar/torchio/issues/1179 for more context about this issue.\n",
      "  warnings.warn(message, stacklevel=1)\n",
      "Running Inference: 100%|██████████| 16/16 [00:11<00:00,  1.44it/s]\n",
      "Running Inference: 100%|██████████| 16/16 [00:10<00:00,  1.52it/s]\n",
      "Running Inference: 100%|██████████| 16/16 [00:10<00:00,  1.50it/s]\n",
      "Running Inference: 100%|██████████| 16/16 [00:10<00:00,  1.50it/s]\n",
      "Running Inference: 100%|██████████| 16/16 [00:10<00:00,  1.50it/s]\n",
      "Running Inference: 100%|██████████| 16/16 [00:10<00:00,  1.52it/s]\n",
      "Running Inference: 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]\n",
      "Running Inference: 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "Running Inference: 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "Running Inference: 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]\n",
      "Running Inference: 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "Running Inference: 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "Running Inference: 100%|██████████| 15/15 [00:09<00:00,  1.53it/s]\n",
      "Running Inference: 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "Running Inference: 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "Running Inference: 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "Running Inference: 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n",
      "Running Inference: 100%|██████████| 15/15 [00:09<00:00,  1.57it/s]\n",
      "Running Inference: 100%|██████████| 4/4 [00:02<00:00,  1.88it/s]\n",
      "Running Inference: 100%|██████████| 4/4 [00:02<00:00,  1.87it/s]\n",
      "Running Inference: 100%|██████████| 4/4 [00:02<00:00,  1.87it/s]\n",
      "Running Inference: 100%|██████████| 4/4 [00:02<00:00,  1.87it/s]\n",
      "Running Inference: 100%|██████████| 4/4 [00:02<00:00,  1.86it/s]\n",
      "Running Inference: 100%|██████████| 4/4 [00:02<00:00,  1.87it/s]\n",
      "Running Inference: 100%|██████████| 8/8 [00:05<00:00,  1.49it/s]\n",
      "Running Inference: 100%|██████████| 8/8 [00:05<00:00,  1.51it/s]\n",
      "Running Inference: 100%|██████████| 8/8 [00:05<00:00,  1.51it/s]\n",
      "Running Inference: 100%|██████████| 8/8 [00:05<00:00,  1.49it/s]\n",
      "Running Inference: 100%|██████████| 8/8 [00:05<00:00,  1.50it/s]\n",
      "Running Inference: 100%|██████████| 8/8 [00:05<00:00,  1.50it/s]\n",
      "Running Inference: 100%|██████████| 10/10 [00:06<00:00,  1.56it/s]\n",
      "Running Inference: 100%|██████████| 10/10 [00:06<00:00,  1.57it/s]\n",
      "Running Inference: 100%|██████████| 10/10 [00:06<00:00,  1.57it/s]\n",
      "Running Inference: 100%|██████████| 10/10 [00:06<00:00,  1.57it/s]\n",
      "Running Inference: 100%|██████████| 10/10 [00:06<00:00,  1.57it/s]\n",
      "Running Inference: 100%|██████████| 10/10 [00:06<00:00,  1.57it/s]\n",
      "Running Inference: 100%|██████████| 13/13 [00:08<00:00,  1.53it/s]\n",
      "Running Inference: 100%|██████████| 13/13 [00:08<00:00,  1.51it/s]\n",
      "Running Inference: 100%|██████████| 13/13 [00:08<00:00,  1.52it/s]\n",
      "Running Inference: 100%|██████████| 13/13 [00:08<00:00,  1.50it/s]\n",
      "Running Inference: 100%|██████████| 13/13 [00:08<00:00,  1.51it/s]\n",
      "Running Inference: 100%|██████████| 13/13 [00:08<00:00,  1.52it/s]\n",
      "Running Inference: 100%|██████████| 22/22 [00:14<00:00,  1.50it/s]\n",
      "Running Inference: 100%|██████████| 22/22 [00:14<00:00,  1.53it/s]\n",
      "Running Inference: 100%|██████████| 22/22 [00:14<00:00,  1.51it/s]\n",
      "Running Inference: 100%|██████████| 22/22 [00:14<00:00,  1.53it/s]\n",
      "Running Inference: 100%|██████████| 22/22 [00:14<00:00,  1.51it/s]\n",
      "Running Inference: 100%|██████████| 22/22 [00:14<00:00,  1.51it/s]\n",
      "Running Inference: 100%|██████████| 40/40 [00:26<00:00,  1.52it/s]\n",
      "Running Inference: 100%|██████████| 40/40 [00:26<00:00,  1.53it/s]\n",
      "Running Inference: 100%|██████████| 40/40 [00:26<00:00,  1.54it/s]\n",
      "Running Inference: 100%|██████████| 40/40 [00:26<00:00,  1.53it/s]\n",
      "Running Inference: 100%|██████████| 40/40 [00:26<00:00,  1.54it/s]\n",
      "Running Inference: 100%|██████████| 40/40 [00:26<00:00,  1.54it/s]\n",
      "Running Inference: 100%|██████████| 40/40 [00:26<00:00,  1.52it/s]\n",
      "Running Inference: 100%|██████████| 40/40 [00:25<00:00,  1.54it/s]\n",
      "Running Inference: 100%|██████████| 40/40 [00:26<00:00,  1.54it/s]\n",
      "Running Inference: 100%|██████████| 40/40 [00:25<00:00,  1.54it/s]\n",
      "Running Inference: 100%|██████████| 40/40 [00:26<00:00,  1.54it/s]\n",
      "Running Inference: 100%|██████████| 40/40 [00:25<00:00,  1.54it/s]\n",
      "Running Inference: 100%|██████████| 8/8 [00:04<00:00,  1.62it/s]\n",
      "Running Inference: 100%|██████████| 8/8 [00:04<00:00,  1.61it/s]\n",
      "Running Inference: 100%|██████████| 8/8 [00:04<00:00,  1.62it/s]\n",
      "Running Inference: 100%|██████████| 8/8 [00:04<00:00,  1.62it/s]\n",
      "Running Inference: 100%|██████████| 8/8 [00:04<00:00,  1.62it/s]\n",
      "Running Inference: 100%|██████████| 8/8 [00:04<00:00,  1.62it/s]\n",
      "Running Inference: 100%|██████████| 4/4 [00:02<00:00,  1.88it/s]\n",
      "Running Inference: 100%|██████████| 4/4 [00:02<00:00,  1.89it/s]\n",
      "Running Inference: 100%|██████████| 4/4 [00:02<00:00,  1.92it/s]\n",
      "Running Inference: 100%|██████████| 4/4 [00:02<00:00,  1.90it/s]\n",
      "Running Inference: 100%|██████████| 4/4 [00:02<00:00,  1.90it/s]\n",
      "Running Inference: 100%|██████████| 4/4 [00:02<00:00,  1.90it/s]\n",
      "Running Inference: 100%|██████████| 12/12 [00:07<00:00,  1.57it/s]\n",
      "Running Inference: 100%|██████████| 12/12 [00:07<00:00,  1.63it/s]\n",
      "Running Inference: 100%|██████████| 12/12 [00:07<00:00,  1.63it/s]\n",
      "Running Inference: 100%|██████████| 12/12 [00:07<00:00,  1.62it/s]\n",
      "Running Inference: 100%|██████████| 12/12 [00:07<00:00,  1.62it/s]\n",
      "Running Inference: 100%|██████████| 12/12 [00:07<00:00,  1.62it/s]\n",
      "Running Inference: 100%|██████████| 23/23 [00:14<00:00,  1.54it/s]\n",
      "Running Inference: 100%|██████████| 23/23 [00:14<00:00,  1.56it/s]\n",
      "Running Inference: 100%|██████████| 23/23 [00:14<00:00,  1.56it/s]\n",
      "Running Inference: 100%|██████████| 23/23 [00:14<00:00,  1.56it/s]\n",
      "Running Inference: 100%|██████████| 23/23 [00:14<00:00,  1.57it/s]\n",
      "Running Inference: 100%|██████████| 23/23 [00:14<00:00,  1.56it/s]\n",
      "Running Inference: 100%|██████████| 16/16 [00:10<00:00,  1.48it/s]\n",
      "Running Inference: 100%|██████████| 16/16 [00:11<00:00,  1.35it/s]\n",
      "Running Inference: 100%|██████████| 16/16 [00:10<00:00,  1.51it/s]\n",
      "Running Inference: 100%|██████████| 16/16 [00:10<00:00,  1.53it/s]\n",
      "Running Inference: 100%|██████████| 16/16 [00:10<00:00,  1.53it/s]\n",
      "Running Inference: 100%|██████████| 16/16 [00:10<00:00,  1.53it/s]\n",
      "Running Inference: 100%|██████████| 5/5 [00:03<00:00,  1.59it/s]\n",
      "Running Inference: 100%|██████████| 5/5 [00:03<00:00,  1.59it/s]\n",
      "Running Inference: 100%|██████████| 5/5 [00:03<00:00,  1.59it/s]\n",
      "Running Inference: 100%|██████████| 5/5 [00:03<00:00,  1.60it/s]\n",
      "Running Inference: 100%|██████████| 5/5 [00:03<00:00,  1.59it/s]\n",
      "Running Inference: 100%|██████████| 5/5 [00:03<00:00,  1.58it/s]\n",
      "Running Inference: 100%|██████████| 12/12 [00:07<00:00,  1.53it/s]\n",
      "Running Inference: 100%|██████████| 12/12 [00:07<00:00,  1.53it/s]\n",
      "Running Inference: 100%|██████████| 12/12 [00:07<00:00,  1.53it/s]\n",
      "Running Inference: 100%|██████████| 12/12 [00:07<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Dice Score is 0.33377110958099365\n",
      "Mean Sensitivity is 0.45256580956879\n"
     ]
    }
   ],
   "source": [
    "prediction_dir_location = \"D:\\\\data_ETIS_781\\\\Training\\\\Predictions\\\\Test_Predictions\\\\SWI_Predictions\\\\Predictions_patients581_gamma2_sigmoid05\"\n",
    "ground_truth_label_location = test_label_dir\n",
    "\n",
    "logits_list = run_inference(test_dataloader, model_for_prediction, (145,145,18), (4, 4, 4), test_dir, return_logits=True)\n",
    "predictions_list = [logit_to_binary_mask(logits, threshold=0.5) for logits in logits_list]\n",
    "save_predictions(predictions_list, prediction_dir_location, ground_truth_label_location)\n",
    "ground_truth_masks_list = load_prediction_masks(ground_truth_label_location)\n",
    "dice_score_list = compute_dice_metric(predictions_list, ground_truth_masks_list)\n",
    "intersection_list = compute_sensitivity_metric(predictions_list, ground_truth_masks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f85ac34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder created at D:\\data_ETIS_781\\Training\\Predictions\\Test_Predictions\\SWI_Predictions\\Predictions_patients581_gamma2_sigmoid04\n",
      "Mean Dice Score is 0.26990097761154175\n",
      "Mean Sensitivity is 0.5677848645299747\n"
     ]
    }
   ],
   "source": [
    "prediction_dir_location = \"D:\\\\data_ETIS_781\\\\Training\\\\Predictions\\\\Test_Predictions\\\\SWI_Predictions\\\\Predictions_patients581_gamma2_sigmoid04\"\n",
    "\n",
    "predictions_list = [logit_to_binary_mask(logits, threshold=0.4) for logits in logits_list]\n",
    "save_predictions(predictions_list, prediction_dir_location, ground_truth_label_location)\n",
    "ground_truth_masks_list = load_prediction_masks(ground_truth_label_location)\n",
    "dice_score_list = compute_dice_metric(predictions_list, ground_truth_masks_list)\n",
    "intersection_list = compute_sensitivity_metric(predictions_list, ground_truth_masks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7fd0c086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "patches = \"581x25\"\n",
    "gamma = 2\n",
    "sigmoid = 0.4\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(12, 5))\n",
    "\n",
    "counts_dice, bins_dice, patches_dice = axs[0].hist(np.array(dice_score_list).flatten(), bins=20)\n",
    "\n",
    "for count, x in zip(counts_dice, bins_dice[:-1]):\n",
    "    axs[0].text(x + 0.02, count, str(int(count)), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "counts_inter, bins_inter, patches_inter = axs[1].hist(np.array(intersection_list).flatten(), bins=20)\n",
    "\n",
    "for count, x in zip(counts_inter, bins_inter[:-1]):\n",
    "    axs[1].text(x + 0.02, count, str(int(count)), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "axs[0].text(0.4, 0.9, f\"Mean Dice = {dice_score_list.mean():.4f}\", transform=axs[0].transAxes)\n",
    "axs[0].set_xlabel(\"Dice Score\")\n",
    "axs[0].set_ylabel(\"Frequency\")\n",
    "axs[0].set_title(f\"Dice Score statistic {patches} patches | gamma {gamma} | sigmoid {sigmoid}\")\n",
    "\n",
    "axs[1].text(0.4, 0.9, f\"Mean Sensitivity = {intersection_list.mean():.4f}\", transform=axs[1].transAxes)\n",
    "axs[1].set_xlabel(\"Sensitivity\")\n",
    "axs[1].set_ylabel(\"Frequency\")\n",
    "axs[1].set_title(f\"Sensitivity statistic {patches} patches | gamma {gamma} | sigmoid {sigmoid}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"D:\\\\data_ETIS_781\\\\Training\\\\Checkpoints\\\\Metrics_Results\\\\MetricsStatistic_{patches}patches_gamma{gamma}_sigmoid0{int(10 * sigmoid)}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e337e4",
   "metadata": {},
   "source": [
    "### Predict from whole images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "659087c6-76ae-44ab-b88f-1f2a46def0d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 512, 512, 24] at entry 0 and [1, 512, 512, 115] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m all_predictions_first \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicted_mask_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_for_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type(\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\u001b[43m}\u001b[49m)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type(\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\u001b[43m}\u001b[49m)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 512, 512, 24] at entry 0 and [1, 512, 512, 115] at entry 1"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "all_predictions_mean = []\n",
    "all_predictions_first = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, test_labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        predicted_mask_test = model_for_prediction(images)\n",
    "\n",
    "        predicted_mask_test_mean = predicted_mask_test.mean(dim=1)\n",
    "        predicted_mask_test_first = predicted_mask_test[:,0,:,:]\n",
    "\n",
    "        all_predictions_mean.append(predicted_mask_test_mean.cpu())\n",
    "        all_predictions_first.append(predicted_mask_test_first.cpu())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14820ab-ee9a-4089-ba50-ed63458882b7",
   "metadata": {},
   "source": [
    "## Testing ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcca993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
