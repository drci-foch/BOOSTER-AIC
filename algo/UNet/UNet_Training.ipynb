{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "102557f9-7184-484b-bd0b-79795636e49b",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7759bce3-13cf-4cda-a6e8-1f01f86b305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchio as tio\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import monai\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b2901c-63ed-44ae-88bd-8bdbaacd7bb4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Filter out problematic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8537031-08db-41d9-8c64-d1fb376c5583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['06-10664-D0MR']\n",
      "['09-10683-D0MR']\n",
      "['09-10890-D0MR']\n",
      "['16-10232-D0MR']\n",
      "['21-10049-D0MR']\n",
      "['21-10049-D0MR']\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\SWI\"\n",
    "problem_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\Problem_Images\\\\SWI\"\n",
    "prev = []\n",
    "for file in os.listdir(source_dir):\n",
    "    number = file.split(\"_\")[1:2]\n",
    "    # if file.split(\"_\")[-1] == \"ph.nii.gz\":\n",
    "    #     ph_q = True\n",
    "    # else:\n",
    "    #     ph_q = False\n",
    "    if (number == prev):\n",
    "        print(number)\n",
    "        #os.rename(os.path.join(source_dir, file), os.path.join(problem_dir, file))\n",
    "    prev = number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "987fa1f8-78da-41d5-a7a2-da18b8b95351",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\TOF3D\"\n",
    "problem_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\Problem_Images\\\\TOF3D\"\n",
    "prev = []\n",
    "for file in os.listdir(source_dir):\n",
    "    number = file.split(\"_\")[1:2]\n",
    "    if \"_\".join(file.split(\"_\")[-2:]) == \"Eq_1.nii.gz\":\n",
    "        eq1_q = True\n",
    "    else:\n",
    "        eq1_q = False\n",
    "    if (number == prev) & (eq1_q):\n",
    "        os.rename(os.path.join(source_dir, file), os.path.join(problem_dir, file))\n",
    "    prev = number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc631a49-7746-496f-9fb5-2e925805c890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'16-10170-D0MR', '02-10871-D0MR', '07-10333-D0MR', '14-10034-D0MR', '21-10163-D0MR', '21-10135-D0MR', '18-10428-D0MR', '01-10221-D0MR', '14-10119-D0MR', '14-10239-D0MR', '06-10750-D0MR', '05-10410-D0MR', '30-10034-D0MR', '18-10183-D0MR', '14-10164-D0MR', '30-10085-D0MR', '06-10487-D0MR', '14-10269-D0MR', '14-10115-D0MR', '18-10542-D0MR', '18-10099-D0MR', '06-10516-D0MR', '09-10890-D0MR', '21-10158-D0MR', '02-10874-D0MR', '30-10091-D0MR', '16-10168-D0MR', '30-10092-D0MR', '30-10090-D0MR', '06-10778-D0MR', '14-10156-D0MR', '02-10555-D0MR', '17-10120-D0MR', '16-10025-D0MR', '14-10172-D0MR', '02-10878-D0MR', '14-10068-D0MR', '06-10769-D0MR', '02-10722-D0MR', '14-10153-D0MR', '14-10238-D0MR', '30-10082-D0MR', '30-10083-D0MR', '07-10335-D0MR', '14-10120-D0MR', '30-10076-D0MR', '18-10396-D0MR', '14-10123-D0MR', '18-10206-D0MR', '14-10173-D0MR', '14-10087-D0MR', '21-10049-D0MR', '30-10088-D0MR', '14-10166-D0MR', '04-10442-D0MR', '14-10125-D0MR', '30-10094-D0MR', '14-10243-D0MR', '09-10674-D0MR', '09-10683-D0MR', '09-10670-D0MR', '30-10068-D0MR', '02-10652-D0MR', '30-10089-D0MR', '02-10653-D0MR', '18-10315-D0MR', '14-10171-D0MR', '04-10209-D0MR', '05-10383-D0MR', '30-10084-D0MR', '18-10037-D0MR', '11-10071-D0MR', '16-10117-D0MR', '18-10150-D0MR', '14-10086-D0MR', '30-10070-D0MR'}\n"
     ]
    }
   ],
   "source": [
    "swi_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\SWI\"\n",
    "mask_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\MASK\"\n",
    "\n",
    "swi_numbers = [file.split(\"_\")[1:2][0] for file in os.listdir(swi_dir)]\n",
    "mask_numbers = [file.split(\"_\")[1:2][0] for file in os.listdir(mask_dir)]\n",
    "\n",
    "diff = set(mask_numbers) - set(swi_numbers)\n",
    "\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "473d4408-8c01-425e-80ba-9a1b0bb3f0c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2018-104_16-10170-D0MR_22_AX_T2_EG.nii.gz\n",
      "Processed 2018-104_02-10871-D0MR_6_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_07-10333-D0MR_20_SWI_Images.nii.gz\n",
      "Processed 2018-104_14-10034-D0MR_5_Ax_T2_.nii.gz\n",
      "Processed 2018-104_21-10163-D0MR_401_cs_T2_FFE.nii.gz\n",
      "Processed 2018-104_21-10135-D0MR_5_Ax_T2_.nii.gz\n",
      "Processed 2018-104_18-10428-D0MR_11_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_01-10221-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_14-10119-D0MR_16_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10239-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_06-10750-D0MR_8_AX_T2_EG_STD.nii.gz\n",
      "Processed 2018-104_05-10410-D0MR_12_t2_fl2d_tra_4mm_hemo_te_25.nii.gz\n",
      "Processed 2018-104_30-10034-D0MR_8_t2_fl2d_ax.nii.gz\n",
      "Processed 2018-104_18-10183-D0MR_12_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10164-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10085-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_06-10487-D0MR_9_AX_T2_EG_STD.nii.gz\n",
      "Processed 2018-104_14-10269-D0MR_16_AX_T2_.nii.gz\n",
      "Processed 2018-104_14-10115-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_18-10542-D0MR_8_AXIAL_T2_EG.nii.gz\n",
      "Processed 2018-104_18-10099-D0MR_5_Ax_T2_4mm.nii.gz\n",
      "Processed 2018-104_06-10516-D0MR_502_eAX_T2_.nii.gz\n",
      "Processed 2018-104_09-10890-D0MR_501_SWI_AVC.nii.gz\n",
      "Processed 2018-104_09-10890-D0MR_501_SWI_AVC_ph.nii.gz\n",
      "Processed 2018-104_21-10158-D0MR_401_cs_T2_FFE.nii.gz\n",
      "Processed 2018-104_02-10874-D0MR_6_Ax_eSWAN_2017.nii.gz\n",
      "Processed 2018-104_30-10091-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_16-10168-D0MR_15_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10092-D0MR_9_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10090-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_06-10778-D0MR_4_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10156-D0MR_6_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_02-10555-D0MR_5_3D_eSWAN_RAPIDE.nii.gz\n",
      "Processed 2018-104_17-10120-D0MR_6_Ax_T2_.nii.gz\n",
      "Processed 2018-104_16-10025-D0MR_12_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10172-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_02-10878-D0MR_5_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10068-D0MR_5_Ax_T2_.nii.gz\n",
      "Processed 2018-104_06-10769-D0MR_13_AX_T2_EG_STD.nii.gz\n",
      "Processed 2018-104_02-10722-D0MR_6_Ax_3D_SWAN+CARTO.nii.gz\n",
      "Processed 2018-104_14-10153-D0MR_5_3D_Ax_SWAN_4mm.nii.gz\n",
      "Processed 2018-104_14-10238-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10082-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10083-D0MR_13_SWI_Images.nii.gz\n",
      "Processed 2018-104_07-10335-D0MR_6_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10120-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10076-D0MR_8_t2_fl2d_ax.nii.gz\n",
      "Processed 2018-104_18-10396-D0MR_12_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10123-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_18-10206-D0MR_11_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10173-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_14-10087-D0MR_5_Ax_SWAN_2.4MM.nii.gz\n",
      "Processed 2018-104_21-10049-D0MR_401_SWIp.nii.gz\n",
      "Processed 2018-104_21-10049-D0MR_401_SWIp_Eq_1.nii.gz\n",
      "Processed 2018-104_21-10049-D0MR_401_SWIp_ph.nii.gz\n",
      "Processed 2018-104_30-10088-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_14-10166-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_04-10442-D0MR_14_T2_EG_TRA.nii.gz\n",
      "Processed 2018-104_14-10125-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10094-D0MR_4_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10243-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_09-10674-D0MR_5_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_09-10683-D0MR_501_SWI_AVC.nii.gz\n",
      "Processed 2018-104_09-10683-D0MR_501_SWI_AVC_ph.nii.gz\n",
      "Processed 2018-104_09-10670-D0MR_502_AXIAL_SWI.nii.gz\n",
      "Processed 2018-104_30-10068-D0MR_8_t2_fl2d_ax.nii.gz\n",
      "Processed 2018-104_02-10652-D0MR_5_Ax_SWAN.nii.gz\n",
      "Processed 2018-104_30-10089-D0MR_15_SWI_Images.nii.gz\n",
      "Processed 2018-104_02-10653-D0MR_13_AX_T2_EG.nii.gz\n",
      "Processed 2018-104_18-10315-D0MR_11_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10171-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_04-10209-D0MR_5_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_05-10383-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10084-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_18-10037-D0MR_501_T2_FFE_CS.nii.gz\n",
      "Processed 2018-104_11-10071-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_16-10117-D0MR_13_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_18-10150-D0MR_14_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10086-D0MR_6_3D_Ax_SWAN.nii.gz\n",
      "Processed 2018-104_30-10070-D0MR_8_t2_fl2d_ax.nii.gz\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"E:\\\\Data_ETIS\\\\THROMBMICS-ALARMS_20240531\"\n",
    "target_dir = \"E:\\\\Data_ETIS\\\\Temp\"\n",
    "\n",
    "for number in list(diff):\n",
    "    for directory in glob.glob(os.path.join(source_dir, \"2018-104_\"+ number, \"T2star_*\")):\n",
    "        for nii_file in os.listdir(directory):\n",
    "            os.rename(os.path.join(directory, nii_file), os.path.join(target_dir, nii_file))\n",
    "            print(\"Processed \"+ nii_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b611b762-ea53-415a-af59-a47a1073ae11",
   "metadata": {},
   "source": [
    "## Separate Test Batch of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85ffd9f8-2f8d-4b13-833a-02053ebea35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "thrombus_mask_train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_labels\\\\MASK_Train\"\n",
    "thrombus_mask_test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Test\"\n",
    "thrombus_mask_val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_labels\\\\MASK_Val\"\n",
    "foreground_mask_train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_labels\\\\MASK_Foreground_Train\"\n",
    "foreground_mask_test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Foreground_Test\"\n",
    "foreground_mask_val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_labels\\\\MASK_Foreground_Val\"\n",
    "swi_train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_dataset\\\\SWI_Train\"\n",
    "swi_test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_dataset\\\\SWI_Test\"\n",
    "swi_val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_dataset\\\\SWI_Val\"\n",
    "tof_train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_dataset\\\\TOF3D_Train\"\n",
    "tof_test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_dataset\\\\TOF3D_Test\"\n",
    "tof_val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_dataset\\\\TOF3D_Val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15cfda5e-2785-4836-ae83-889a9c3680ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_image_batch(thrombus_mask_source, thrombus_mask_destination, foreground_mask_source, foreground_mask_destination, swi_source, swi_destination, tof_source, tof_destination, batch_size, seed_value=777):\n",
    "    # Separate four source folders, thrombus mask(labels) , brain foreground masks with thrombus, swi images, tof images into four other destination folders (e.g. validation or test),\n",
    "    # sending the specified number of images selected randomly.\n",
    "    random.seed(seed_value)\n",
    "    batch_indexes = random.sample(range(len(os.listdir(thrombus_mask_source))), batch_size)\n",
    "\n",
    "    thrombus_mask_file_list = [os.listdir(thrombus_mask_source)[index] for index in batch_indexes]\n",
    "    for file in thrombus_mask_file_list:\n",
    "        os.rename(os.path.join(thrombus_mask_source, file), os.path.join(thrombus_mask_destination, file))\n",
    "\n",
    "    foreground_mask_file_list = [os.listdir(foreground_mask_source)[index] for index in batch_indexes]\n",
    "    for file in foreground_mask_file_list:\n",
    "        os.rename(os.path.join(foreground_mask_source, file), os.path.join(foreground_mask_destination, file))\n",
    "    \n",
    "    swi_file_list = [os.listdir(swi_source)[index] for index in batch_indexes]\n",
    "    for file in swi_file_list:\n",
    "        os.rename(os.path.join(swi_source, file), os.path.join(swi_destination, file))\n",
    "\n",
    "    tof_file_list = [os.listdir(tof_source)[index] for index in batch_indexes]\n",
    "    for file in tof_file_list:\n",
    "        os.rename(os.path.join(tof_source, file), os.path.join(tof_destination, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e1d3c-9c23-403f-8526-00efb1ca3d63",
   "metadata": {},
   "source": [
    "Separate test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "626d9491-7bfb-4bd3-9313-97dbe1b65efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_image_batch(thrombus_mask_train_dir, thrombus_mask_test_dir, foreground_mask_train_dir, foreground_mask_test_dir, swi_train_dir, swi_test_dir, tof_train_dir, tof_test_dir, 100, seed_value=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2501cdcb-4fc7-469c-bfe0-68f0386c28d6",
   "metadata": {},
   "source": [
    "Separate validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9ceb8cf-3ec5-480f-89c3-db6377789c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_image_batch(thrombus_mask_train_dir, thrombus_mask_val_dir, foreground_mask_train_dir, foreground_mask_val_dir, swi_train_dir, swi_val_dir, tof_train_dir, tof_val_dir, 181, seed_value=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192edc50-ce79-4d19-92b1-9c341d8a235c",
   "metadata": {},
   "source": [
    "Clear out the training folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a6f313a-6428-4483-930a-0dd5d31811e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_training_folders(thrombus_mask_train_dir, thrombus_mask_test_dir, thrombus_mask_val_dir, foreground_mask_train_dir, foreground_mask_test_dir, foreground_mask_val_dir, swi_train_dir, swi_test_dir, swi_val_dir, tof_train_dir, tof_test_dir, tof_val_dir):\n",
    "    # Remove files from training, validation and test folders of labels, foreground masks, swi images and tof images.\n",
    "    folder_list = [thrombus_mask_train_dir, thrombus_mask_test_dir, thrombus_mask_val_dir, foreground_mask_train_dir, foreground_mask_test_dir, foreground_mask_val_dir, swi_train_dir, swi_test_dir, swi_val_dir, tof_train_dir, tof_test_dir, tof_val_dir]\n",
    "    for folders in folder_list:\n",
    "        for file in os.listdir(folders):\n",
    "            os.remove(os.path.join(folders, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc04a0dc-cf1a-4b8c-af61-c0d3111a7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_training_folders(thrombus_mask_train_dir, thrombus_mask_test_dir, thrombus_mask_val_dir, foreground_mask_train_dir, foreground_mask_test_dir, foreground_mask_val_dir, swi_train_dir, swi_test_dir, swi_val_dir, tof_train_dir, tof_test_dir, tof_val_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f50055-f8bf-4c98-be7f-72b256862585",
   "metadata": {},
   "source": [
    "Fill training folders from processed images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d97d0b10-438e-4df8-a04c-3ae0c5b33db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_training_folders(source_dir, thrombus_mask_train_dir, swi_train_dir, tof_train_dir):\n",
    "    # Send images from a source folder containing MASK, SWI and TOF3D folders to the training folders.\n",
    "    for folders in os.listdir(source_dir):\n",
    "        if (folders.split(\"_\")[0] == \"MASK\") | (folders == \"MASK\"):\n",
    "            for files in os.listdir(os.path.join(source_dir, folders)):\n",
    "                os.rename(os.path.join(source_dir, folders, files), os.path.join(thrombus_mask_train_dir,files))\n",
    "        elif folders.split(\"_\")[0] == \"SWI\":\n",
    "            for files in os.listdir(os.path.join(source_dir, folders)):\n",
    "                os.rename(os.path.join(source_dir, folders, files), os.path.join(swi_train_dir,files))\n",
    "        elif folders.split(\"_\")[0] == \"TOF3D\":\n",
    "            for files in os.listdir(os.path.join(source_dir, folders)):\n",
    "                os.rename(os.path.join(source_dir, folders, files), os.path.join(tof_train_dir,files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "245da8d3-712e-4e64-ae11-09e365713ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"D:\\\\data_ETIS_781\\\\Resized\"\n",
    "\n",
    "fill_training_folders(source_dir, thrombus_mask_train_dir, swi_train_dir, tof_train_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7944ba3-9b36-425b-a661-8cbbfd62772b",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "870e295a-7037-4fe4-9bfc-9e00b95faaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_array_to_nifti1(array, original_img_path, destination_path, output_name):\n",
    "    # Transform the array to a nifti image which requires the affine of the original image.\n",
    "    processed_img = nib.Nifti1Image(array, nib.load(original_img_path).affine)\n",
    "    \n",
    "    nib.save(processed_img, os.path.join(destination_path, output_name))\n",
    "\n",
    "def remove_padding_from_tensor(tensor, original_dims):\n",
    "    # Apply the padding removal function to the tensor to restore the original dimensions\n",
    "    current_dims = tensor.shape[-len(original_dims):]\n",
    "    resized_tensor = tensor\n",
    "    \n",
    "    for dim, (original_size, current_size) in enumerate(zip(original_dims, current_dims), start=-len(original_dims)):\n",
    "        total_padding = current_size - original_size\n",
    "        padding_before = total_padding // 2\n",
    "        \n",
    "        resized_tensor = torch.narrow(resized_tensor, dim, padding_before, original_size)\n",
    "    return resized_tensor\n",
    "\n",
    "def logit_to_binary_mask(tensor, threshold=0.5):\n",
    "    # Transform a tensor of logits into a binary mask according to the specified probability threshold.\n",
    "    mask_tensor = torch.sigmoid(tensor)\n",
    "\n",
    "    return (mask_tensor >= threshold).float()\n",
    "\n",
    "def restore_inference_original_size (prediction_list, original_img_dir):\n",
    "    return [torch.squeeze(\n",
    "        remove_padding_from_tensor(prediction, nib.load(os.path.join(original_img_dir, original_file)).shape)\n",
    "        )\n",
    "        for prediction, original_file in zip(prediction_list, os.listdir(original_img_dir))\n",
    "        ]\n",
    "\n",
    "def load_prediction_masks (mask_dir):\n",
    "    return [torch.tensor(nib.load(os.path.join(mask_dir, mask)).get_fdata()) for mask in os.listdir(mask_dir) if (mask.endswith(\".nii.gz\"))]\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, filepath):\n",
    "    # Saves a checkpoint of a PyTorch model.\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }\n",
    "    torch.save(checkpoint, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76050939-e922-464c-ae1d-addada7e527d",
   "metadata": {},
   "source": [
    "## 3D Segmentation Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f20d5-1181-44bc-91c2-dd43cd2a574d",
   "metadata": {},
   "source": [
    "### Use the SubjectsDataset class from torchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfe9e0e0-5ee9-4620-8b7c-f4ecfd5a49be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HighToleranceSubject(tio.Subject):\n",
    "    # A custom instance of Subject with higher tolerance in attribute checking.\n",
    "    def check_consistent_attribute(self, *args, **kwargs) -> None:\n",
    "        kwargs['relative_tolerance'] = 1e-4\n",
    "        kwargs['absolute_tolerance'] = 1e-4\n",
    "        return super().check_consistent_attribute(*args, **kwargs)\n",
    "\n",
    "def load_subjectsdataset_1channel (swi_dir, thrombus_labels_dir, foreground_labels_dir, **kwargs):\n",
    "    subjects_list = []\n",
    "    swi_list = os.listdir(swi_dir)\n",
    "    thrombus_labels_list = os.listdir(thrombus_labels_dir)\n",
    "    foreground_labels_list = os.listdir(foreground_labels_dir)\n",
    "    \n",
    "    if len(swi_list) != len(thrombus_labels_list) != len(foreground_labels_list):\n",
    "        print(\"Mismatch in sample numbers\")\n",
    "    \n",
    "    for swi_file, thrombus_label_file, foreground_label_file in zip(swi_list, thrombus_labels_list, foreground_labels_list):\n",
    "        subject = HighToleranceSubject(\n",
    "            swi_image=tio.ScalarImage(os.path.join(swi_dir, swi_file)),\n",
    "            thrombus_label = tio.LabelMap(os.path.join(thrombus_labels_dir, thrombus_label_file)),\n",
    "            foreground_label = tio.LabelMap(os.path.join(foreground_labels_dir, foreground_label_file)),\n",
    "            subject_number = \"_\".join(swi_file.split(\"_\")[:2])\n",
    "        )\n",
    "        subjects_list.append(subject)\n",
    "    \n",
    "    return tio.SubjectsDataset(subjects_list, **kwargs)\n",
    "\n",
    "def load_subjectsdataset_2channel (swi_dir, tof_dir, thrombus_labels_dir, foreground_labels_dir, **kwargs):\n",
    "    subjects_list = []\n",
    "    swi_list = os.listdir(swi_dir)\n",
    "    tof_list = os.listdir(tof_dir)\n",
    "    thrombus_labels_list = os.listdir(thrombus_labels_dir)\n",
    "    foreground_labels_list = os.listdir(foreground_labels_dir)\n",
    "    \n",
    "    if len(swi_list) != len(tof_list) != len(thrombus_labels_list) != len(foreground_labels_list):\n",
    "        print(\"Mismatch in sample numbers\")\n",
    "    \n",
    "    for swi_file, tof_file, thrombus_label_file, foreground_label_file in zip(swi_list, tof_list, thrombus_labels_list, foreground_labels_list):\n",
    "        subject = HighToleranceSubject(\n",
    "            swi_image=tio.ScalarImage(os.path.join(swi_dir, swi_file)),\n",
    "            tof_image=tio.ScalarImage(os.path.join(tof_dir, tof_file)),\n",
    "            thrombus_label = tio.LabelMap(os.path.join(thrombus_labels_dir, thrombus_label_file)),\n",
    "            foreground_label = tio.LabelMap(os.path.join(foreground_labels_dir, foreground_label_file)),\n",
    "            subject_number = \"_\".join(swi_file.split(\"_\")[:2])\n",
    "        )\n",
    "        subjects_list.append(subject)\n",
    "    \n",
    "    return tio.SubjectsDataset(subjects_list, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48623be8-971b-4b85-b794-76cc963d23d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_train\\\\SWI_Train\"\n",
    "tof_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_train\\\\TOF3D_Train\"\n",
    "thrombus_labels_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_labels\\\\MASK_Train\"\n",
    "foreground_labels_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_labels\\\\MASK_Foreground_Train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "913d27eb-e3b9-436c-bb91-6501c7e302f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tio_dataset = load_subjectsdataset_1channel(swi_dir, thrombus_labels_dir, foreground_labels_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22be69e4-08b9-46b1-8420-dbddd5c2f88b",
   "metadata": {},
   "source": [
    "### Setup Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce12750e-23cf-4046-82f4-ec96e8c72e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "tio_sampler = tio.data.LabelSampler(patch_size=(145,145,18), label_name=\"foreground_label\", label_probabilities={0: 0, 1: 0.95, 2: 0.05})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33359195",
   "metadata": {},
   "outputs": [],
   "source": [
    "queue_length = 7000\n",
    "samples_per_volume = 1500\n",
    "\n",
    "tio_patches_queue = tio.Queue(tio_dataset, queue_length, samples_per_volume, tio_sampler, num_workers=0)\n",
    "\n",
    "tio_patches_loader = torch.utils.data.DataLoader(tio_patches_queue, batch_size=6, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d998e6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'29.6 GiB'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tio.Queue.get_max_memory_pretty(tio_patches_queue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c693769",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df1b33e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNetPlusPlus features: (32, 32, 64, 128, 256, 32).\n"
     ]
    }
   ],
   "source": [
    "model = monai.networks.nets.BasicUNetPlusPlus(spatial_dims=3, in_channels=1, out_channels=1, features=(32,32,64,128,256,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcc47e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_loss = monai.losses.FocalLoss(gamma=5, alpha=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9eeb88ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3a28e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Training Loss: 0.0000\n",
      "Epoch 1/20, Validation Loss: 0.0001\n",
      "Epoch 2/20, Training Loss: 0.0000\n",
      "Epoch 2/20, Validation Loss: 0.0000\n",
      "Epoch 3/20, Training Loss: 0.0000\n",
      "Epoch 3/20, Validation Loss: 0.0000\n",
      "Epoch 4/20, Training Loss: 0.0000\n",
      "Epoch 4/20, Validation Loss: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 20\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tio_patches_loader)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Training Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for patches_batch in tio_patches_loader:\n",
    "        images = patches_batch[\"swi_image\"][tio.DATA]\n",
    "        gt_masks = patches_batch[\"thrombus_label\"][tio.DATA]\n",
    "        images, gt_masks = images.to(device), gt_masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predicted_mask = model(images)[0]\n",
    "        loss = focal_loss(predicted_mask, gt_masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(tio_patches_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for patches_batch in tio_patches_loader:\n",
    "            images = patches_batch[\"swi_image\"][tio.DATA]\n",
    "            gt_masks = patches_batch[\"thrombus_label\"][tio.DATA]\n",
    "            images, gt_masks = images.to(device), gt_masks.to(device)\n",
    "            \n",
    "            predicted_mask = model(images)[0]\n",
    "            loss = focal_loss(predicted_mask, gt_masks)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(tio_patches_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}\")\n",
    "    save_checkpoint(model, optimizer, epoch, loss, 'D:\\\\data_ETIS_781\\\\Training\\\\Checkpoints\\\\tio_test_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63f7e43-2794-4de5-97ee-940fc19c2a7e",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f931dec7-85a1-4e05-b9df-07a8896f28c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp3d.UnetPlusPlus(encoder_name=\"resnext50_32x4d\", encoder_weights=\"imagenet\", in_channels=2, classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6626034-0625-4563-bb86-3297f30c5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = smp.losses.DiceLoss(\"binary\", from_logits=False, smooth=1)\n",
    "focal_loss = smp.losses.FocalLoss(\"binary\", alpha=0.75, gamma=2, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8e86064-3999-4ee0-94c5-82a77c0054b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc27b33f-5880-464d-88f7-f0824e9e9d39",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m images, gt_masks \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), gt_masks\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 13\u001b[0m predicted_mask \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m dice_loss(predicted_mask, gt_masks)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m## Average the predictions in each channel\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\segmentation_models_pytorch_3d\\base\\model.py:46\u001b[0m, in \u001b[0;36mSegmentationModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input_shape(x)\n\u001b[0;32m     45\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[1;32m---> 46\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msegmentation_head(decoder_output)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassification_head \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\segmentation_models_pytorch_3d\\decoders\\unetplusplus\\decoder.py:129\u001b[0m, in \u001b[0;36mUnetPlusPlusDecoder.forward\u001b[1;34m(self, *features)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m depth_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth \u001b[38;5;241m-\u001b[39m layer_idx):\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 129\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdepth_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdepth_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdepth_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdepth_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m         dense_x[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdepth_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdepth_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\segmentation_models_pytorch_3d\\decoders\\unetplusplus\\decoder.py:38\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[1;34m(self, x, skip)\u001b[0m\n\u001b[0;32m     36\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(x, scale_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m skip \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention1(x)\n\u001b[0;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, gt_masks in train_dataloader:\n",
    "        images, gt_masks = images.to(device), gt_masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predicted_mask = model(images)\n",
    "        loss = dice_loss(predicted_mask, gt_masks)\n",
    "        ## Average the predictions in each channel\n",
    "        predicted_mask = predicted_mask.mean(dim=1)\n",
    "        # Transform prediction logits to probabilities\n",
    "        predicted_mask = torch.sigmoid(predicted_mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, gt_masks in val_dataloader:\n",
    "            images, gt_masks = images.to(device), gt_masks.to(device)\n",
    "            \n",
    "            predicted_mask = model(images)\n",
    "            ## Average the predictions in each channel\n",
    "            predicted_mask = predicted_mask.mean(dim=1)\n",
    "            # Transform prediction logits to probabilities\n",
    "            predicted_mask = torch.sigmoid(predicted_mask)\n",
    "            loss = dice_loss(predicted_mask, gt_masks)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a3d5d1-8a9b-46bf-ba0b-a40014a7d8ec",
   "metadata": {},
   "source": [
    "## Load model and predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b6f014",
   "metadata": {},
   "source": [
    "### Predict from patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7206679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNetPlusPlus features: (32, 32, 64, 128, 256, 32).\n"
     ]
    }
   ],
   "source": [
    "model_for_prediction = monai.networks.nets.BasicUNetPlusPlus(spatial_dims=3, in_channels=1, out_channels=1, features=(32,32,64,128,256,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6304d2f-4cb8-4eea-9d90-a50fc1206ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer_for_prediction = torch.optim.Adam(model_for_prediction.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05bb09cc-90dc-4a06-ba88-90161cf6916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_prediction_checkpoint = torch.load('D:\\\\data_ETIS_781\\\\Training\\\\Checkpoints\\\\tio_test_10_gamma5_thrombus05_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24ef5435-17bc-4791-92aa-61bb462af246",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_prediction.load_state_dict(model_for_prediction_checkpoint[\"model_state_dict\"])\n",
    "optimizer_for_prediction.load_state_dict(model_for_prediction_checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac5185ba-212b-4a01-8807-ee56a4a2ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_train\\\\SWI_Train\"\n",
    "train_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_labels\\\\MASK_Train\"\n",
    "train_foreground_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Torchio_labels\\\\MASK_Foreground_Train\"\n",
    "val_dir = \"\"\n",
    "val_label_dir = \"\"\n",
    "val_foreground_label_dir = \"\"\n",
    "test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_dataset\\\\SWI_Test\"\n",
    "test_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Test\"\n",
    "test_foreground_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Foreground_Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "554c9d05-434f-4d38-ae29-16face140bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = load_subjectsdataset_1channel (train_dir, train_label_dir, train_foreground_label_dir)\n",
    "#val_dataset = load_subjectsdataset_1channel (val_dir, val_label_dir, val_foreground_label_dir)\n",
    "test_dataset = load_subjectsdataset_1channel (test_dir, test_label_dir, test_foreground_label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff07c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate_fn(batch):\n",
    "    # Collate function to ensure batches have the same size, that is the size of the largest image in the batch.\n",
    "    # Find the max shape in each dimension from the batch\n",
    "    max_dims = [max([subject['swi_image'][tio.DATA].shape[-3:][d] for subject in batch]) for d in range(3)]\n",
    "    \n",
    "    # Apply padding to each image in the batch to match the largest dimensions\n",
    "    padded_subjects = []\n",
    "    for subject in batch:\n",
    "        subject_image = subject['swi_image'][tio.DATA]  # Get the image tensor\n",
    "        \n",
    "        # Calculate how much padding is needed for each dimension\n",
    "        padding = []\n",
    "        for max_dim, current_size in zip(max_dims, subject_image.shape[-3:]):\n",
    "            total_padding = max_dim - current_size\n",
    "            # Divide padding evenly across both sides\n",
    "            padding_before = total_padding // 2\n",
    "            padding_after = total_padding - padding_before  # Handle the case where the difference is odd\n",
    "            padding.extend([padding_before, padding_after])\n",
    "                \n",
    "        # Apply padding to the image\n",
    "        pad_transform = tio.Pad(padding)\n",
    "        padded_image = pad_transform(subject['swi_image'])\n",
    "        \n",
    "        # Create a new Subject with the padded image\n",
    "        padded_subject = tio.Subject(swi_image=tio.ScalarImage(tensor=padded_image[tio.DATA]))\n",
    "        padded_subjects.append(padded_subject)\n",
    "    \n",
    "    return padded_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "023a5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=6, collate_fn=pad_collate_fn, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e35164cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_for_prediction = model_for_prediction.to(device)\n",
    "\n",
    "patch_overlap = 4, 4, 4\n",
    "patch_size = 145,145,18\n",
    "inference_dataloader = test_dataloader\n",
    "logit_threshold = 0.5\n",
    "test_dir_location = test_dir\n",
    "prediction_dir_location = \"D:\\\\data_ETIS_781\\\\Training\\\\Predictions\\\\Test_Predictions\\\\SWI_Predictions\\\\Predictions_patients10_gamma5_thrombus05\"\n",
    "\n",
    "whole_image_predictions = []\n",
    "\n",
    "for batch in inference_dataloader:\n",
    "    for subject in batch:\n",
    "        grid_sampler = tio.inference.GridSampler(subject, patch_size, patch_overlap)\n",
    "        patch_loader = tio.SubjectsLoader(grid_sampler, batch_size=10)\n",
    "        aggregator = tio.inference.GridAggregator(grid_sampler)\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            for patches_batch in patch_loader:\n",
    "                input_tensor = patches_batch[\"swi_image\"][tio.DATA].to(device)\n",
    "                locations = patches_batch[tio.LOCATION]\n",
    "                logits = model_for_prediction(input_tensor)[0]\n",
    "                logits = logits.cpu()\n",
    "                labels = logit_to_binary_mask(logits, threshold=logit_threshold)\n",
    "                aggregator.add_batch(labels, locations)\n",
    "        whole_prediction = aggregator.get_output_tensor().cpu()\n",
    "        whole_image_predictions.append(whole_prediction)\n",
    "original_size_predictions = restore_inference_original_size(whole_image_predictions, test_dir_location)\n",
    "\n",
    "for mask, filename in zip(original_size_predictions, os.listdir(test_dir_location)):\n",
    "    output_mask_name = \"_\".join(filename.split(\"_\")[:2]) + \"_Prediction\" + \".nii.gz\"\n",
    "    save_array_to_nifti1(np.array(mask), os.path.join(test_dir, filename), prediction_dir_location, output_mask_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "74f54790",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mask, filename in zip(original_size_predictions, os.listdir(test_dir)):\n",
    "    output_mask_name = \"_\".join(filename.split(\"_\")[:2]) + \"_Prediction\" + \".nii.gz\"\n",
    "    save_array_to_nifti1(np.array(mask), os.path.join(test_dir, filename), \"D:\\\\data_ETIS_781\\\\Training\\\\Predictions\\\\Test_Predictions\\\\SWI_Predictions\\\\Predictions_patients10_gamma5_thrombus05\", output_mask_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "277c5628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prediction_masks (mask_dir):\n",
    "    return [torch.tensor(nib.load(os.path.join(mask_dir, mask)).get_fdata()) for mask in os.listdir(mask_dir) if (mask.endswith(\".nii.gz\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f7aea995",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list = load_prediction_masks(\"D:\\\\data_ETIS_781\\\\Training\\\\Predictions\\\\Test_Predictions\\\\SWI_Predictions\\\\Predictions_patients10_gamma5_thrombus05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3ee3986f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([480, 640, 80])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_list[4].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e337e4",
   "metadata": {},
   "source": [
    "### Predict from whole images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "659087c6-76ae-44ab-b88f-1f2a46def0d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 512, 512, 24] at entry 0 and [1, 512, 512, 115] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m all_predictions_first \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicted_mask_test\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_for_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type(\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\u001b[43m}\u001b[49m)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type(\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\u001b[43m}\u001b[49m)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 512, 512, 24] at entry 0 and [1, 512, 512, 115] at entry 1"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "all_predictions_mean = []\n",
    "all_predictions_first = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, test_labels in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        predicted_mask_test = model_for_prediction(images)\n",
    "\n",
    "        predicted_mask_test_mean = predicted_mask_test.mean(dim=1)\n",
    "        predicted_mask_test_first = predicted_mask_test[:,0,:,:]\n",
    "\n",
    "        all_predictions_mean.append(predicted_mask_test_mean.cpu())\n",
    "        all_predictions_first.append(predicted_mask_test_first.cpu())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14820ab-ee9a-4089-ba50-ed63458882b7",
   "metadata": {},
   "source": [
    "## Testing ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcca993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
