{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "102557f9-7184-484b-bd0b-79795636e49b",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7759bce3-13cf-4cda-a6e8-1f01f86b305c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wijflo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "import segmentation_models_pytorch_3d as smp3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b2901c-63ed-44ae-88bd-8bdbaacd7bb4",
   "metadata": {},
   "source": [
    "## Filter out problematic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8537031-08db-41d9-8c64-d1fb376c5583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['06-10664-D0MR']\n",
      "['09-10683-D0MR']\n",
      "['09-10890-D0MR']\n",
      "['16-10232-D0MR']\n",
      "['21-10049-D0MR']\n",
      "['21-10049-D0MR']\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\SWI\"\n",
    "problem_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\Problem_Images\\\\SWI\"\n",
    "prev = []\n",
    "for file in os.listdir(source_dir):\n",
    "    number = file.split(\"_\")[1:2]\n",
    "    # if file.split(\"_\")[-1] == \"ph.nii.gz\":\n",
    "    #     ph_q = True\n",
    "    # else:\n",
    "    #     ph_q = False\n",
    "    if (number == prev):\n",
    "        print(number)\n",
    "        #os.rename(os.path.join(source_dir, file), os.path.join(problem_dir, file))\n",
    "    prev = number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "987fa1f8-78da-41d5-a7a2-da18b8b95351",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\TOF3D\"\n",
    "problem_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\Problem_Images\\\\TOF3D\"\n",
    "prev = []\n",
    "for file in os.listdir(source_dir):\n",
    "    number = file.split(\"_\")[1:2]\n",
    "    if \"_\".join(file.split(\"_\")[-2:]) == \"Eq_1.nii.gz\":\n",
    "        eq1_q = True\n",
    "    else:\n",
    "        eq1_q = False\n",
    "    if (number == prev) & (eq1_q):\n",
    "        os.rename(os.path.join(source_dir, file), os.path.join(problem_dir, file))\n",
    "    prev = number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc631a49-7746-496f-9fb5-2e925805c890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'16-10170-D0MR', '02-10871-D0MR', '07-10333-D0MR', '14-10034-D0MR', '21-10163-D0MR', '21-10135-D0MR', '18-10428-D0MR', '01-10221-D0MR', '14-10119-D0MR', '14-10239-D0MR', '06-10750-D0MR', '05-10410-D0MR', '30-10034-D0MR', '18-10183-D0MR', '14-10164-D0MR', '30-10085-D0MR', '06-10487-D0MR', '14-10269-D0MR', '14-10115-D0MR', '18-10542-D0MR', '18-10099-D0MR', '06-10516-D0MR', '09-10890-D0MR', '21-10158-D0MR', '02-10874-D0MR', '30-10091-D0MR', '16-10168-D0MR', '30-10092-D0MR', '30-10090-D0MR', '06-10778-D0MR', '14-10156-D0MR', '02-10555-D0MR', '17-10120-D0MR', '16-10025-D0MR', '14-10172-D0MR', '02-10878-D0MR', '14-10068-D0MR', '06-10769-D0MR', '02-10722-D0MR', '14-10153-D0MR', '14-10238-D0MR', '30-10082-D0MR', '30-10083-D0MR', '07-10335-D0MR', '14-10120-D0MR', '30-10076-D0MR', '18-10396-D0MR', '14-10123-D0MR', '18-10206-D0MR', '14-10173-D0MR', '14-10087-D0MR', '21-10049-D0MR', '30-10088-D0MR', '14-10166-D0MR', '04-10442-D0MR', '14-10125-D0MR', '30-10094-D0MR', '14-10243-D0MR', '09-10674-D0MR', '09-10683-D0MR', '09-10670-D0MR', '30-10068-D0MR', '02-10652-D0MR', '30-10089-D0MR', '02-10653-D0MR', '18-10315-D0MR', '14-10171-D0MR', '04-10209-D0MR', '05-10383-D0MR', '30-10084-D0MR', '18-10037-D0MR', '11-10071-D0MR', '16-10117-D0MR', '18-10150-D0MR', '14-10086-D0MR', '30-10070-D0MR'}\n"
     ]
    }
   ],
   "source": [
    "swi_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\SWI\"\n",
    "mask_dir = \"D:\\\\THROMBMICS-ALARMS_20240531\\\\MASK\"\n",
    "\n",
    "swi_numbers = [file.split(\"_\")[1:2][0] for file in os.listdir(swi_dir)]\n",
    "mask_numbers = [file.split(\"_\")[1:2][0] for file in os.listdir(mask_dir)]\n",
    "\n",
    "diff = set(mask_numbers) - set(swi_numbers)\n",
    "\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "473d4408-8c01-425e-80ba-9a1b0bb3f0c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 2018-104_16-10170-D0MR_22_AX_T2_EG.nii.gz\n",
      "Processed 2018-104_02-10871-D0MR_6_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_07-10333-D0MR_20_SWI_Images.nii.gz\n",
      "Processed 2018-104_14-10034-D0MR_5_Ax_T2_.nii.gz\n",
      "Processed 2018-104_21-10163-D0MR_401_cs_T2_FFE.nii.gz\n",
      "Processed 2018-104_21-10135-D0MR_5_Ax_T2_.nii.gz\n",
      "Processed 2018-104_18-10428-D0MR_11_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_01-10221-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_14-10119-D0MR_16_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10239-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_06-10750-D0MR_8_AX_T2_EG_STD.nii.gz\n",
      "Processed 2018-104_05-10410-D0MR_12_t2_fl2d_tra_4mm_hemo_te_25.nii.gz\n",
      "Processed 2018-104_30-10034-D0MR_8_t2_fl2d_ax.nii.gz\n",
      "Processed 2018-104_18-10183-D0MR_12_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10164-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10085-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_06-10487-D0MR_9_AX_T2_EG_STD.nii.gz\n",
      "Processed 2018-104_14-10269-D0MR_16_AX_T2_.nii.gz\n",
      "Processed 2018-104_14-10115-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_18-10542-D0MR_8_AXIAL_T2_EG.nii.gz\n",
      "Processed 2018-104_18-10099-D0MR_5_Ax_T2_4mm.nii.gz\n",
      "Processed 2018-104_06-10516-D0MR_502_eAX_T2_.nii.gz\n",
      "Processed 2018-104_09-10890-D0MR_501_SWI_AVC.nii.gz\n",
      "Processed 2018-104_09-10890-D0MR_501_SWI_AVC_ph.nii.gz\n",
      "Processed 2018-104_21-10158-D0MR_401_cs_T2_FFE.nii.gz\n",
      "Processed 2018-104_02-10874-D0MR_6_Ax_eSWAN_2017.nii.gz\n",
      "Processed 2018-104_30-10091-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_16-10168-D0MR_15_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10092-D0MR_9_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10090-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_06-10778-D0MR_4_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10156-D0MR_6_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_02-10555-D0MR_5_3D_eSWAN_RAPIDE.nii.gz\n",
      "Processed 2018-104_17-10120-D0MR_6_Ax_T2_.nii.gz\n",
      "Processed 2018-104_16-10025-D0MR_12_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10172-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_02-10878-D0MR_5_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10068-D0MR_5_Ax_T2_.nii.gz\n",
      "Processed 2018-104_06-10769-D0MR_13_AX_T2_EG_STD.nii.gz\n",
      "Processed 2018-104_02-10722-D0MR_6_Ax_3D_SWAN+CARTO.nii.gz\n",
      "Processed 2018-104_14-10153-D0MR_5_3D_Ax_SWAN_4mm.nii.gz\n",
      "Processed 2018-104_14-10238-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10082-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10083-D0MR_13_SWI_Images.nii.gz\n",
      "Processed 2018-104_07-10335-D0MR_6_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10120-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10076-D0MR_8_t2_fl2d_ax.nii.gz\n",
      "Processed 2018-104_18-10396-D0MR_12_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10123-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_18-10206-D0MR_11_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10173-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_14-10087-D0MR_5_Ax_SWAN_2.4MM.nii.gz\n",
      "Processed 2018-104_21-10049-D0MR_401_SWIp.nii.gz\n",
      "Processed 2018-104_21-10049-D0MR_401_SWIp_Eq_1.nii.gz\n",
      "Processed 2018-104_21-10049-D0MR_401_SWIp_ph.nii.gz\n",
      "Processed 2018-104_30-10088-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_14-10166-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_04-10442-D0MR_14_T2_EG_TRA.nii.gz\n",
      "Processed 2018-104_14-10125-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_30-10094-D0MR_4_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_14-10243-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_09-10674-D0MR_5_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_09-10683-D0MR_501_SWI_AVC.nii.gz\n",
      "Processed 2018-104_09-10683-D0MR_501_SWI_AVC_ph.nii.gz\n",
      "Processed 2018-104_09-10670-D0MR_502_AXIAL_SWI.nii.gz\n",
      "Processed 2018-104_30-10068-D0MR_8_t2_fl2d_ax.nii.gz\n",
      "Processed 2018-104_02-10652-D0MR_5_Ax_SWAN.nii.gz\n",
      "Processed 2018-104_30-10089-D0MR_15_SWI_Images.nii.gz\n",
      "Processed 2018-104_02-10653-D0MR_13_AX_T2_EG.nii.gz\n",
      "Processed 2018-104_18-10315-D0MR_11_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10171-D0MR_5_Ax_T2_GRE_rapide.nii.gz\n",
      "Processed 2018-104_04-10209-D0MR_5_Ax_T2_GRE.nii.gz\n",
      "Processed 2018-104_05-10383-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_30-10084-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_18-10037-D0MR_501_T2_FFE_CS.nii.gz\n",
      "Processed 2018-104_11-10071-D0MR_11_SWI_Images.nii.gz\n",
      "Processed 2018-104_16-10117-D0MR_13_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_18-10150-D0MR_14_T2_EG_AX.nii.gz\n",
      "Processed 2018-104_14-10086-D0MR_6_3D_Ax_SWAN.nii.gz\n",
      "Processed 2018-104_30-10070-D0MR_8_t2_fl2d_ax.nii.gz\n"
     ]
    }
   ],
   "source": [
    "source_dir = \"E:\\\\Data_ETIS\\\\THROMBMICS-ALARMS_20240531\"\n",
    "target_dir = \"E:\\\\Data_ETIS\\\\Temp\"\n",
    "\n",
    "for number in list(diff):\n",
    "    for directory in glob.glob(os.path.join(source_dir, \"2018-104_\"+ number, \"T2star_*\")):\n",
    "        for nii_file in os.listdir(directory):\n",
    "            os.rename(os.path.join(directory, nii_file), os.path.join(target_dir, nii_file))\n",
    "            print(\"Processed \"+ nii_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b611b762-ea53-415a-af59-a47a1073ae11",
   "metadata": {},
   "source": [
    "## Separate Test Batch of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85ffd9f8-2f8d-4b13-833a-02053ebea35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_labels\\\\MASK_Train\"\n",
    "mask_test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_labels\\\\MASK_Test\"\n",
    "mask_val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_labels\\\\MASK_Val\"\n",
    "swi_train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_dataset\\\\SWI_Train\"\n",
    "swi_test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_dataset\\\\SWI_Test\"\n",
    "swi_val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_dataset\\\\SWI_Val\"\n",
    "tof_train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_dataset\\\\TOF3D_Train\"\n",
    "tof_test_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Test_dataset\\\\TOF3D_Test\"\n",
    "tof_val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_dataset\\\\TOF3D_Val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15cfda5e-2785-4836-ae83-889a9c3680ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_image_batch(mask_source, mask_destination, swi_source, swi_destination, tof_source, tof_destination, batch_size, seed_value=777):\n",
    "    random.seed(seed_value)\n",
    "    batch_indexes = random.sample(range(len(os.listdir(mask_source))), batch_size)\n",
    "\n",
    "    mask_file_list = [os.listdir(mask_source)[index] for index in batch_indexes]\n",
    "    for file in mask_file_list:\n",
    "        os.rename(os.path.join(mask_source, file), os.path.join(mask_destination, file))\n",
    "\n",
    "    swi_file_list = [os.listdir(swi_source)[index] for index in batch_indexes]\n",
    "    for file in swi_file_list:\n",
    "        os.rename(os.path.join(swi_source, file), os.path.join(swi_destination, file))\n",
    "\n",
    "    tof_file_list = [os.listdir(tof_source)[index] for index in batch_indexes]\n",
    "    for file in tof_file_list:\n",
    "        os.rename(os.path.join(tof_source, file), os.path.join(tof_destination, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e1d3c-9c23-403f-8526-00efb1ca3d63",
   "metadata": {},
   "source": [
    "Separate test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "626d9491-7bfb-4bd3-9313-97dbe1b65efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_image_batch(mask_train_dir, mask_test_dir, swi_train_dir, swi_test_dir, tof_train_dir, tof_test_dir, 100, seed_value=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2501cdcb-4fc7-469c-bfe0-68f0386c28d6",
   "metadata": {},
   "source": [
    "Separate validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9ceb8cf-3ec5-480f-89c3-db6377789c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "separate_image_batch(mask_train_dir, mask_val_dir, swi_train_dir, swi_val_dir, tof_train_dir, tof_val_dir, 181, seed_value=777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64519bc-2edf-41d6-822f-c6aab492b64c",
   "metadata": {},
   "source": [
    "Train command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76050939-e922-464c-ae1d-addada7e527d",
   "metadata": {},
   "source": [
    "## Use segmentation models 3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c72051-e9ef-493e-92b3-3ed2ef397e56",
   "metadata": {},
   "source": [
    "### Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83bebbf3-5d8d-4890-a460-10ea9eafe3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicImageDataset3D(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir, label_dir, transform=None, target_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.img_path_list = [[os.path.join(path, img) for img in files if img.endswith(\".nii.gz\")]\n",
    "                         for path, dirs, files in os.walk(self.img_dir) if path != self.img_dir]\n",
    "        self.label_path_list = [mask for mask in os.listdir(self.label_dir) if mask.endswith(\".nii.gz\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_path_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array([nib.load(img[idx]).get_fdata() for img in self.img_path_list])\n",
    "        label = nib.load(os.path.join(self.label_dir, self.label_path_list[idx])).get_fdata()\n",
    "\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f34b7dfc-8c86-4bca-ae73-f91e5838f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_dataset\\\\\"\n",
    "val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_dataset\"\n",
    "train_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_labels\\\\MASK_Train\"\n",
    "val_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_labels\\\\MASK_Val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f004094-a1a6-49ee-817c-b6984a10a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadToMultipleofN3D(object):\n",
    "    def __init__(self, multiple_n):\n",
    "        self.multiple_n = multiple_n\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        height, width, depth = img.shape[1:4]\n",
    "        pad_height = (self.multiple_n - height % self.multiple_n) % self.multiple_n\n",
    "        pad_width = (self.multiple_n - width % self.multiple_n) % self.multiple_n\n",
    "        pad_depth = (self.multiple_n - depth % self.multiple_n) % self.multiple_n\n",
    "\n",
    "        padding = (0, pad_depth, 0, pad_height, 0, pad_width)\n",
    "\n",
    "        padded_img = torch.nn.functional.pad(img, padding, mode=\"constant\", value=0)\n",
    "        return padded_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e21ece5e-c824-4fd9-898a-815927f2aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BasicImageDataset3D(train_dir, train_label_dir, transform=PadToMultipleofN3D(32))\n",
    "val_dataset = BasicImageDataset3D(val_dir, val_label_dir, transform=PadToMultipleofN3D(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cfe2ffd6-e85e-4406-b55f-0c898601598a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63f7e43-2794-4de5-97ee-940fc19c2a7e",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f931dec7-85a1-4e05-b9df-07a8896f28c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp3d.UnetPlusPlus(encoder_name=\"resnext50_32x4d\", encoder_weights=\"imagenet\", in_channels=2, classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6626034-0625-4563-bb86-3297f30c5304",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = smp3d.losses.DiceLoss(\"binary\", smooth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8e86064-3999-4ee0-94c5-82a77c0054b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc27b33f-5880-464d-88f7-f0824e9e9d39",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 810. MiB for an array with shape (2, 768, 768, 90) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      8\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m----> 9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_masks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_masks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_masks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[34], line 15\u001b[0m, in \u001b[0;36mBasicImageDataset3D.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 15\u001b[0m     image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([nib\u001b[38;5;241m.\u001b[39mload(img[idx])\u001b[38;5;241m.\u001b[39mget_fdata() \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_path_list])\n\u001b[0;32m     16\u001b[0m     label \u001b[38;5;241m=\u001b[39m nib\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_path_list[idx]))\u001b[38;5;241m.\u001b[39mget_fdata()\n\u001b[0;32m     18\u001b[0m     image \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(image, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 810. MiB for an array with shape (2, 768, 768, 90) and data type float64"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, gt_masks in train_dataloader:\n",
    "        images, gt_masks = images.to(device), gt_masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predicted_mask = model(images)\n",
    "        loss = dice_loss(predicted_mask, gt_masks)\n",
    "        ## Average the predictions in each channel\n",
    "        predicted_mask = predicted_mask.mean(dim=1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, gt_masks in val_dataloader:\n",
    "            images, gt_masks = images.to(device), gt_masks.to(device)\n",
    "            \n",
    "            predicted_mask = model(images)\n",
    "            ## Average the predictions in each channel\n",
    "            predicted_mask = predicted_mask.mean(dim=1)\n",
    "            loss = dice_loss(predicted_mask, gt_masks)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433444e5-e469-409c-8e18-294e6975eac1",
   "metadata": {},
   "source": [
    "## Use pytorch segmentation models slice-by-slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cac5af-f0df-43ad-a5c2-ffba7c2d4d1a",
   "metadata": {},
   "source": [
    "### Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd1e31f1-3511-451a-b074-0f70f60078ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicImageDataset2D(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir, label_dir, transform=None, target_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.img_path_list = [[os.path.join(path, img) for img in files if img.endswith(\".nii.gz\")]\n",
    "                         for path, dirs, files in os.walk(self.img_dir) if path != self.img_dir]\n",
    "        self.label_path_list = [mask for mask in os.listdir(self.label_dir) if mask.endswith(\".nii.gz\")]\n",
    "        ## Assume all images have same dimensions by retrieving the dimensions of first image only.\n",
    "        self.img_depth = nib.load(os.path.join(self.label_dir, self.label_path_list[0])).shape[2] \n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.label_path_list) * self.img_depth)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_idx = idx // self.img_depth\n",
    "        slice_idx = idx % self.img_depth\n",
    "        img_slice = np.array([nib.load(img[img_idx]).get_fdata()[:,:,slice_idx] for img in self.img_path_list])\n",
    "        label_slice = nib.load(os.path.join(self.label_dir, self.label_path_list[img_idx])).get_fdata()[:,:,slice_idx]\n",
    "\n",
    "        img_slice = torch.tensor(img_slice, dtype=torch.float32)\n",
    "        label_slice = torch.tensor(label_slice, dtype=torch.float32)\n",
    "        if self.transform:\n",
    "            img_slice = self.transform(img_slice)\n",
    "        if self.target_transform:\n",
    "            label_slice = self.target_transform(label_slice)\n",
    "        return img_slice, label_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15309a40-42fb-4ba9-afcf-1dbecaf09c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_dataset\\\\\"\n",
    "val_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_dataset\"\n",
    "train_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Train_labels\\\\MASK_Train\"\n",
    "val_label_dir = \"D:\\\\data_ETIS_781\\\\Training\\\\Validation_labels\\\\MASK_Val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f45c95a1-c54a-451e-aee0-9b40a839999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadToMultipleofN2D(object):\n",
    "    def __init__(self, multiple_n):\n",
    "        self.multiple_n = multiple_n\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        height, width = img.shape[1:3]\n",
    "        pad_height = (self.multiple_n - height % self.multiple_n) % self.multiple_n\n",
    "        pad_width = (self.multiple_n - width % self.multiple_n) % self.multiple_n\n",
    "\n",
    "        padding = (0, pad_height, 0, pad_width)\n",
    "\n",
    "        padded_img = torch.nn.functional.pad(img, padding, mode=\"constant\", value=0)\n",
    "        return padded_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d402ace6-fd3d-4ee6-85d0-0608c7f2a24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BasicImageDataset2D(train_dir, train_label_dir, transform=PadToMultipleofN2D(32))\n",
    "val_dataset = BasicImageDataset2D(val_dir, val_label_dir, transform=PadToMultipleofN2D(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c8494a3-4714-433e-a1b4-a967e1e2e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6adae1a-8c1e-45d0-b2c2-300514a1b0ed",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ffde041-bf34-4a0b-a3dc-2c7795e7c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.UnetPlusPlus(encoder_name=\"resnext50_32x4d\", encoder_weights=\"imagenet\", in_channels=2, classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff608029-926c-481c-bf8b-7481b538277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_loss = smp.losses.DiceLoss(\"binary\", smooth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74ee2cb0-ad34-4c55-99de-975eb651a1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cac1a2eb-f1c5-435e-9bb4-e29debc30efe",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      8\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m----> 9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_masks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_masks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_masks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m, in \u001b[0;36mBasicImageDataset2D.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     17\u001b[0m img_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_depth\n\u001b[0;32m     18\u001b[0m slice_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_depth\n\u001b[1;32m---> 19\u001b[0m img_slice \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43m[\u001b[49m\u001b[43mnib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimg_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_fdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mslice_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_path_list\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     20\u001b[0m label_slice \u001b[38;5;241m=\u001b[39m nib\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_path_list[img_idx]))\u001b[38;5;241m.\u001b[39mget_fdata()[:,:,slice_idx]\n\u001b[0;32m     22\u001b[0m img_slice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(img_slice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     17\u001b[0m img_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_depth\n\u001b[0;32m     18\u001b[0m slice_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_depth\n\u001b[1;32m---> 19\u001b[0m img_slice \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mnib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimg_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_fdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:,:,slice_idx] \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_path_list])\n\u001b[0;32m     20\u001b[0m label_slice \u001b[38;5;241m=\u001b[39m nib\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_dir, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_path_list[img_idx]))\u001b[38;5;241m.\u001b[39mget_fdata()[:,:,slice_idx]\n\u001b[0;32m     22\u001b[0m img_slice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(img_slice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nibabel\\dataobj_images.py:373\u001b[0m, in \u001b[0;36mDataobjImage.get_fdata\u001b[1;34m(self, caching, dtype)\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fdata_cache\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# Always return requested data type\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# For array proxies, will attempt to confine data array to dtype\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# during scaling\u001b[39;00m\n\u001b[1;32m--> 373\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataobj, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m caching \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfill\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fdata_cache \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nibabel\\arrayproxy.py:457\u001b[0m, in \u001b[0;36mArrayProxy.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    437\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read data from file and apply scaling, casting to ``dtype``\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \n\u001b[0;32m    439\u001b[0m \u001b[38;5;124;03m    If ``dtype`` is unspecified, the dtype of the returned array is the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;124;03m        Scaled image data with type `dtype`.\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_scaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslicer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m         arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nibabel\\arrayproxy.py:424\u001b[0m, in \u001b[0;36mArrayProxy._get_scaled\u001b[1;34m(self, dtype, slicer)\u001b[0m\n\u001b[0;32m    422\u001b[0m     scl_inter \u001b[38;5;241m=\u001b[39m scl_inter\u001b[38;5;241m.\u001b[39mastype(use_dtype)\n\u001b[0;32m    423\u001b[0m \u001b[38;5;66;03m# Read array and upcast as necessary for big slopes, intercepts\u001b[39;00m\n\u001b[1;32m--> 424\u001b[0m scaled \u001b[38;5;241m=\u001b[39m apply_read_scaling(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_unscaled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslicer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslicer\u001b[49m\u001b[43m)\u001b[49m, scl_slope, scl_inter)\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    426\u001b[0m     scaled \u001b[38;5;241m=\u001b[39m scaled\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mpromote_types(scaled\u001b[38;5;241m.\u001b[39mdtype, dtype), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nibabel\\arrayproxy.py:394\u001b[0m, in \u001b[0;36mArrayProxy._get_unscaled\u001b[1;34m(self, slicer)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m canonical_slicers(slicer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m==\u001b[39m canonical_slicers(\n\u001b[0;32m    391\u001b[0m     (), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    392\u001b[0m ):\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 394\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_from_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m            \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj:\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fileslice(\n\u001b[0;32m    404\u001b[0m         fileobj,\n\u001b[0;32m    405\u001b[0m         slicer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    410\u001b[0m         lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock,\n\u001b[0;32m    411\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\nibabel\\volumeutils.py:465\u001b[0m, in \u001b[0;36marray_from_file\u001b[1;34m(shape, in_dtype, infile, offset, order, mmap)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(infile, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    464\u001b[0m     data_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(n_bytes)\n\u001b[1;32m--> 465\u001b[0m     n_read \u001b[38;5;241m=\u001b[39m \u001b[43minfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m     needs_copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\gzip.py:301\u001b[0m, in \u001b[0;36mGzipFile.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01merrno\u001b[39;00m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(errno\u001b[38;5;241m.\u001b[39mEBADF, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread() on write-only GzipFile object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer\u001b[38;5;241m.\u001b[39mread(size)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[1;32m---> 68\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\gzip.py:507\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# Read a chunk of data from the file\u001b[39;00m\n\u001b[0;32m    505\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE)\n\u001b[1;32m--> 507\u001b[0m uncompress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mprepend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, gt_masks in train_dataloader:\n",
    "        images, gt_masks = images.to(device), gt_masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predicted_mask = model(images)\n",
    "        ## Average the predictions in each channel\n",
    "        predicted_mask = predicted_mask.mean(dim=1)\n",
    "        loss = dice_loss(predicted_mask, gt_masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, gt_masks in val_dataloader:\n",
    "            images, gt_masks = images.to(device), gt_masks.to(device)\n",
    "            \n",
    "            predicted_mask = model(images)\n",
    "            ## Average the predictions in each channel\n",
    "            predicted_mask = predicted_mask.mean(dim=1)\n",
    "            loss = dice_loss(predicted_mask, gt_masks)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(val_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfef89ca-1925-4ad2-8d15-d6e131118a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad91f15-66ae-46d5-a356-df44f343ca83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
